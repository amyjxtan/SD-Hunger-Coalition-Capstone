{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd9994f",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "## 1.1 Table of Contents\n",
    "- 1. **Introduction**\n",
    "    - 1.1 Table of Contents\n",
    "    - 1.2 Background\n",
    "    - 1.3 Hypotheses\n",
    "- 2. **Redefining the FPL (Federal Poverty Line)**\n",
    "- 3. **Predicting CalFresh Meals**\n",
    "    - 3.1 Data Cleaning/Wrangling\n",
    "    - 3.2 Visualizing Total CalFresh Allotments\n",
    "    - 3.3 Multiple Linear Regression Models\n",
    "    - 3.4 Multiple Linear Regression Model Predictions\n",
    "- 4. **Predicting Total School Meals**\n",
    "    - 4.1 Data Cleaning/Wrangling\n",
    "    - 4.2 Visualizing Total School Meals\n",
    "    - 4.3 Ordinal Piecewise Regression\n",
    "    - 4.4 DCT (Discrete Cosine Transform) Models\n",
    "- 5. **Discussion and Conclusion**\n",
    "    - 5.1 Limitations\n",
    "    - 5.2 Future Areas of Research\n",
    "- 6. **Citations**\n",
    "- 7. **Appendix**\n",
    "## 1.2 Background\n",
    "In San Diego County, nutrition insecurity remains a pressing challenge affecting approximately 813k residents as of June 2024, with disproportionate impacts on children, individuals living with disabilities, and people of color. The San Diego Hunger Coalition (SDHC) actively leads collaborative efforts to address this crisis through research, education, and advocacy, working toward ensuring every individual has access to three culturally appropriate and nutritious meals daily.\n",
    "\n",
    "The SDHC currently identifies and defines nutrition insecurity using a threshold of 200% of the Federal Poverty Level (FPL). Their methodology, collaboratively developed and approved by the Hunger-Free Advisory Board, and data are used by many San Diego organizations to identify regions in the county where additional aid and support are needed, advocate for legislative and administrative policies to increase access to healthy, nutritious food, and develop more efficient, equitable networks of food assistance programs. Their work not only benefits San Diego County, but their methodology also informs other organizations' methodologies and efforts to combat nutrition insecurity.\n",
    "\n",
    "However, recent economic indicators suggest this threshold may need adjustment. SDHC data shows that nutrition insecurity rates have increased from 22% during the pandemic to 25% as of June 2024. Rising inflation has outpaced wage growth over the past four years, leading to increased household debt, while the unemployment rate reached 5% in August, leaving 70k residents struggling to find sufficient work. Additionally, as of February 2024, MIT's Living Wage Calculator indicated that a single individual in San Diego County needed to earn approximately 61k annually to meet basic needs; meanwhile, the current 200% FPL threshold indicates that a family of four needs to earn around 62k annually to meet basic needs. This stark difference between the annual incomes needed for a single individual versus a family of four suggests that the 200% FPL threshold may be an underestimate, making it necessary to redefine the FPL threshold for nutrition insecurity. The MIT calculator suggests that the true threshold for nutrition security might be closer to 300% of the federal poverty level, a threshold that a report on food insecurity conducted by USC for LA County also utilized in their estimates.\n",
    "\n",
    "Beyond the FPL threshold consideration, SDHC faces additional challenges. Currently, the organization operates with a four-month data lag in their reporting and analysis—data from June, for example, can only be fully processed, explained, and modeled by November. This delay impacts their ability to respond quickly to changing needs in the community. Furthermore, as SDHC plays a crucial role in advocacy, they must effectively communicate complex data to diverse stakeholders to encourage involvement in and support equitable policies.\n",
    "\n",
    "## 1.3 Hypotheses\n",
    "\n",
    "These challenges have motivated our capstone project, which aims to enhance SDHC's ability to identify and serve nutrition-insecure households more effectively, forecast needs more accurately, and communicate findings more clearly to drive evidence-based decision-making. Specifically, we aim to address two key questions to strengthen SDHC's data-informed approach to eliminating the meal gap in San Diego County:\n",
    "1. What FPL threshold best identifies households experiencing nutrition insecurity?\n",
    "2. How can predictive models be developed and implemented to forecast different types of food assistance in real time or in advance, to reduce the current reporting time lag of approximately four months?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b051335",
   "metadata": {},
   "source": [
    "# 2. Redefining the FPL (Federal Poverty Line)\n",
    "\n",
    "In regards to our first hypothesis, SDHC’s current methodology uses a threshold of 200% of the national federal poverty level (FPL) to define the nutrition-insecure population in San Diego County. However, recently the SDHC has been working on adjusting the FPL guidelines to reflect the consumer price index (CPI) of San Diego County due to a notable difference between the San Diego inflation rate and the national average inflation rate. \n",
    "\n",
    "To preface, the SDHC methodology primarily draws data from the HHS (Department of Health and Human Services) Poverty Guidelines, which is used by federal programs, such as SNAP, to determine financial eligibility. The guidelines are a simplified version of the federal poverty thresholds, which are mainly used for the purposes of calculating official poverty population statistics rather than being an eligibility determiner. The annual poverty guideline is derived by adjusting the poverty threshold of the previous year using the national inflation rate percent change.\n",
    "\n",
    "$$\\text{FPL}_{y}= \\text{FPL}_{y-1} * (1+\\text{InflationRate}_{y})$$\n",
    "\n",
    "Where:\n",
    "* $\\text{FPL}_{y}$ =  FPL in year *y*\n",
    "* $\\text{FPL}_{y-1}$ =  FPL in previous year *y*\n",
    "* $\\text{InflationRate}_{t}$ =  Annual percent change in CPI\n",
    "\n",
    "\n",
    "Although there is CPI data available starting from 1965, we begin with 1982 to stay consistent to the U.S. City Average CPI indexing used by the U.S. Bureau of Labor Statistics, 1982-84=100 (U.S. Bureau of Labor Statistics).\n",
    "\n",
    "To calculate the San Diego adjusted FPL we begin with the use of the national FPL guidelines provided by HHS and San Diego CPI, starting from the set base year of 1982 for a single person and a family of four. \n",
    "\n",
    "1. First, adjust for San Diego Inflation, by multiplying the FPL from the previous year by the CPI yearly increase starting from the year 1982. \n",
    "2. Then scale the results by 2 to reflect the 200% FPL. \n",
    "3. Finally, adjust for a 200% FPL reflecting the inflation rate of San Diego County by dividing the adjusted value by the 100% national FPL. \n",
    "\n",
    "Through this workflow the SDHC is able to conclude that for the year of 2024, the FPL of 224% is the appropriate equivalent to the national FPL of 200%. Moving forward, the FPL used as a threshold for nutrition insecurity for the SDHC's methodology will be placed at 225%. \n",
    "\n",
    "This new FPL threshold will go on to aid in the calculations of the Meal Gap - the number of meals people still need after food assistance and self-purchased meals - alongside the predictive models to reduce the reporting time lag.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The relevant spreadsheet with computations can be found [here](https://docs.google.com/spreadsheets/d/1HxMOou5nV6W-9J6lFjfJKSUw0dLezKr7zqH4-IHeVWU/edit?usp=sharing).\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Predicting CalFresh Meals\n",
    "\n",
    "In regards to our second hypothesis, we examined models for two different types of nutrition assistance since the San Diego Hunger Coalition conducts quarterly updates on hunger, nutrition insecurity, food assistance, poverty, and the remaning meal gap in San Diego County. We specifically focused on CalFresh allotments and school meals for the scope of this project. In this section, we explore options to predict CalFresh assistance. The following predictive model aims to predict the monthly CalFresh allotments for San Diego County to reduce the current reporting time lag of 4 months.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6364a0-890f-4252-9351-063758a2904e",
   "metadata": {},
   "source": [
    "## 3.1 Data Cleaning/ Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77c880-791e-479e-bced-dbcd9aeb4a02",
   "metadata": {},
   "source": [
    "The data we are working with is the Total CalFresh Regular Issuances from the County of San Diego, spanning between the years 2022 to 2024. The data contains the dollar amount issued in CalFresh benefits per zip code in the county. \n",
    "\n",
    "SDHC's vision is to create a table with the sum total of all zip issuances, which would then allow us the ability to predict the dollar amount of CalFresh benefits for the each month. \n",
    "\n",
    "Below we will clean all datasets and merge them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2210b435-97c5-4ca4-b27b-148764007da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "135be49b-590d-4dbc-bd04-3dbac63e82f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/calfresh_data/Jan_May2022.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load in datasets, provided by County of San Diego\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 2022 (JAN-DEC) CalFresh Regular Issuances by Zip Code Data\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m jan_may22 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/calfresh_data/Jan_May2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m june22 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/calfresh_data/June2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m Q3_22 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/calfresh_data/Q3_22.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/calfresh_data/Jan_May2022.csv'"
     ]
    }
   ],
   "source": [
    "# load in datasets, provided by County of San Diego\n",
    "\n",
    "# 2022 (JAN-DEC) CalFresh Regular Issuances by Zip Code Data\n",
    "jan_may22 = pd.read_csv('data/calfresh_data/Jan_May2022.csv')\n",
    "june22 = pd.read_csv('data/calfresh_data/June2022.csv')\n",
    "Q3_22 = pd.read_csv('data/calfresh_data/Q3_22.csv')\n",
    "Q4_22 = pd.read_csv('data/calfresh_data/Q4_22.csv')\n",
    "\n",
    "# 2023 (JAN-DEC) CalFresh Regular Issuances by Zip Code Data\n",
    "Q1_23 = pd.read_csv('data/calfresh_data/Q1_23.csv')\n",
    "Q2_23 = pd.read_csv('data/calfresh_data/Q2_23.csv')\n",
    "Q3_23 = pd.read_csv('data/calfresh_data/Q3_23.csv')\n",
    "Q4_23 = pd.read_csv('data/calfresh_data/Q4_23.csv')\n",
    "\n",
    "# 2024 (JAN-DEC) CalFresh Regular Issuances by Zip Code Data\n",
    "Q1_24 = pd.read_csv('data/calfresh_data/Q1_24.csv')\n",
    "Q2_24 = pd.read_csv('data/calfresh_data/Q2_24.csv')\n",
    "Q3_24 = pd.read_csv('data/calfresh_data/Q3_24.csv')\n",
    "Q4_24 = pd.read_csv('data/calfresh_data/Q4_24.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8cb65-aee2-4ca6-922a-8f6c95de3ae2",
   "metadata": {},
   "source": [
    "We first create a dictionary and a couple of functions to extract the month and year from date columns in various formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758754a-6b46-4d0e-82d7-c9c633ab1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, \n",
    "          'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "\n",
    "def get_month_MY(date):\n",
    "    \"\"\"\n",
    "    Extracts the month from a string in the format \"Month, Year.\" and uses the months dictionary to \n",
    "    return it's respective numerical value\n",
    "    \n",
    "    Args: \n",
    "        date (str): a string in the format \"Month, Year\"\n",
    "    \n",
    "    Returns:\n",
    "        month (int): the numerical month\n",
    "    \"\"\"\n",
    "    month = months[date.split(\" \")[0]]\n",
    "    return month\n",
    "\n",
    "def get_year_MY(date):\n",
    "    \"\"\"\n",
    "    Extracts the year from a string in the format \"Month, Year.\"\n",
    "    \n",
    "    Args: \n",
    "        date(str): a string in the format \"Month, Year\"\n",
    "    \n",
    "    Returns:\n",
    "        year(int): the year\n",
    "    \"\"\"\n",
    "    year = int(date.split(\" \")[1])\n",
    "    return year\n",
    "\n",
    "def get_month_MDY(date):\n",
    "    \"\"\"\n",
    "    Extracts the month from a string in the format \"Month/Day/Year\" and returns it as an integer.\n",
    "    \n",
    "    Args: \n",
    "        date(str): a date in the format \"Month/Day/Year\"\n",
    "    \n",
    "    Returns:\n",
    "        month(int): the numerical month\n",
    "    \"\"\"\n",
    "    month = int(date.split(\"/\")[0])\n",
    "    return month\n",
    "    \n",
    "\n",
    "def get_year_MDY(date):\n",
    "    \"\"\"\n",
    "    Extracts the year from a string in the format \"Month/Day/Year\" and returns it as an integer.\n",
    "    \n",
    "    Args: \n",
    "        date(str): a date in the format \"Month/Day/Year\"\n",
    "    \n",
    "    Returns:\n",
    "        year(int): the year\n",
    "    \"\"\"\n",
    "    year = int(date.split(\"/\")[2])\n",
    "    return year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39183c3a-83a9-43fb-b7f8-73a16e00b5bb",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2022: Jan to May "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaeaa0d-b456-4f54-ad3f-a5d2eaa0452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# jan_may22.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f4273-17cb-499a-a892-5f1c1f714a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values\n",
    "jan_may_22 = jan_may22.dropna()\n",
    "\n",
    "#take out January data duplicate\n",
    "jan_may_22 = jan_may_22.drop('Unnamed: 2', axis=1)\n",
    "\n",
    "# checking current column names\n",
    "jan_may_22.columns\n",
    "\n",
    "# renaming columns\n",
    "jan_may_22 = jan_may_22.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 1': 'Jan 2022', \n",
    "                                'Unnamed: 3': 'Feb 2022', \n",
    "                                'Unnamed: 4': 'Mar 2022', \n",
    "                                'Unnamed: 5': 'Apr 2022', \n",
    "                                'Unnamed: 6': 'May 2022'})\n",
    "\n",
    "#Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Jan 2022', 'Feb 2022', 'Mar 2022', 'Apr 2022', 'May 2022']:\n",
    "    jan_may_22[month] = jan_may_22[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "#sum all the rows for each column and reset index\n",
    "totals_jan_may22 = jan_may_22[['Jan 2022', 'Feb 2022', 'Mar 2022', 'Apr 2022', 'May 2022']].sum().reset_index()\n",
    "\n",
    "#rename columns\n",
    "totals_jan_may22.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code \n",
    "\n",
    "# converting to string\n",
    "totals_jan_may22['Date'] = totals_jan_may22['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totals_jan_may22['month'] = totals_jan_may22['Date'].apply(get_month_MY)\n",
    "totals_jan_may22['year'] = totals_jan_may22['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totals_jan_may22 = totals_jan_may22[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totals_jan_may22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f12a7-4986-4f56-829d-11273663a935",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2022: June "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bd787-4305-4e41-9005-b3084ab6335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# june22.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626da0d2-0504-4288-b94e-7f06b87689c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "june_22 = june22[['Unnamed: 0', 'Unnamed: 1']]\n",
    "\n",
    "# renaming columns\n",
    "june_22 = june_22.rename(columns={'Unnamed: 0': 'ZipCode', 'Unnamed: 1': 'Jun 2022'})\n",
    "\n",
    "# drop rows with missing values \n",
    "june_22 = june_22.dropna(subset=['ZipCode', 'Jun 2022'])\n",
    "\n",
    "# drop unnecessary rows\n",
    "june_22 = june_22.drop([5, 6])\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "june_22['Jun 2022'] = june_22['Jun 2022'].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totals_june22 = june_22[['Jun 2022']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totals_june22.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code\n",
    "\n",
    "# converting to string\n",
    "totals_june22['Date'] = totals_june22['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totals_june22['month'] = totals_june22['Date'].apply(get_month_MY)\n",
    "totals_june22['year'] = totals_june22['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totals_june22 = totals_june22[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totals_june22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73198b-e143-44ed-99e9-41437ccedbef",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2022: July to September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4a3ea-faca-4d01-aff9-f5434eaa0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# Q3_22.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2432ced-c135-4f55-9406-97c075eb5ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "Q3_2022 = Q3_22[['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']]\n",
    "\n",
    "# renaming columns\n",
    "Q3_2022 = Q3_2022.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 1': 'Jul 2022', \n",
    "                                'Unnamed: 2': 'Aug 2022', \n",
    "                                'Unnamed: 3': 'Sep 2022'\n",
    "                               })\n",
    "\n",
    "# drop rows with missing values \n",
    "Q3_2022 = Q3_2022.dropna(subset=['ZipCode', 'Jul 2022', 'Aug 2022', 'Sep 2022'], how='all')\n",
    "\n",
    "# drop unnecessary rows\n",
    "Q3_2022 = Q3_2022.drop([1, 5, 6])\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Jul 2022', 'Aug 2022', 'Sep 2022']:\n",
    "    Q3_2022[month] = Q3_2022[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totalsQ3_22 = Q3_2022[['Jul 2022', 'Aug 2022', 'Sep 2022']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totalsQ3_22.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code \n",
    "\n",
    "# converting to string\n",
    "totalsQ3_22['Date'] = totalsQ3_22['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totalsQ3_22['month'] = totalsQ3_22['Date'].apply(get_month_MY)\n",
    "totalsQ3_22['year'] = totalsQ3_22['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totalsQ3_22 = totalsQ3_22[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totalsQ3_22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912dffd-3b02-4fed-bf24-6a42672dd2f0",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2022: October to December "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190609a-49ed-4240-9ede-37ec4bfab3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# Q4_22.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3bc82b-d9da-4da4-9a47-f0780bc918e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "Q4_2022 = Q4_22[['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']]\n",
    "\n",
    "# renaming columns\n",
    "Q4_2022 = Q4_2022.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 1': 'Oct 2022', \n",
    "                                'Unnamed: 2': 'Nov 2022', \n",
    "                                'Unnamed: 3': 'Dec 2022'\n",
    "                               })\n",
    "\n",
    "# drop rows with missing values \n",
    "Q4_2022 = Q4_2022.dropna(subset=['ZipCode', 'Oct 2022', 'Nov 2022', 'Dec 2022'], how='all')\n",
    "\n",
    "# drop unnecessary rows\n",
    "Q4_2022 = Q4_2022.drop([1, 5, 6])\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Oct 2022', 'Nov 2022', 'Dec 2022']:\n",
    "    Q4_2022[month] = Q4_2022[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totalsQ4_22 = Q4_2022[['Oct 2022', 'Nov 2022', 'Dec 2022']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totalsQ4_22.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code\n",
    "\n",
    "# converting to string\n",
    "totalsQ4_22['Date'] = totalsQ4_22['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totalsQ4_22['month'] = totalsQ4_22['Date'].apply(get_month_MY)\n",
    "totalsQ4_22['year'] = totalsQ4_22['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totalsQ4_22 = totalsQ4_22[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totalsQ4_22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5c703-0d3a-4aef-9b49-89ab010efdf7",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2023: January to March  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c33e4-3f8a-4915-9459-4c5cfd2e1e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# Q1_23.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c62ef1-a087-42d2-a98c-c1c38fd8c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "Q1_2023 = Q1_23[['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']]\n",
    "\n",
    "# renaming columns\n",
    "Q1_2023 = Q1_2023.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 1': 'Jan 2023', \n",
    "                                'Unnamed: 2': 'Feb 2023', \n",
    "                                'Unnamed: 3': 'Mar 2023'\n",
    "                               })\n",
    "\n",
    "# drop rows with missing values \n",
    "Q1_2023 = Q1_2023.dropna(subset=['ZipCode', 'Jan 2023', 'Feb 2023', 'Mar 2023'], how='all')\n",
    "\n",
    "# drop unnecessary rows\n",
    "Q1_2023 = Q1_2023.drop([1, 4, 5])\n",
    "\n",
    "#  remove row where ZipCode column has 'Grand Total'                       \n",
    "Q1_2023 = Q1_2023[Q1_2023['ZipCode'] != 'Grand Total']\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Jan 2023', 'Feb 2023', 'Mar 2023']:\n",
    "    Q1_2023[month] = Q1_2023[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totalsQ1_23 = Q1_2023[['Jan 2023', 'Feb 2023', 'Mar 2023']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totalsQ1_23.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code given by Amy \n",
    "\n",
    "# converting to string\n",
    "totalsQ1_23['Date'] = totalsQ1_23['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totalsQ1_23['month'] = totalsQ1_23['Date'].apply(get_month_MY)\n",
    "totalsQ1_23['year'] = totalsQ1_23['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totalsQ1_23 = totalsQ1_23[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totalsQ1_23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1312d1-cc74-4d39-af24-de12c4732504",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2023: April to June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537173a-fe58-43ba-b7a0-cf9cbefac221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# Q2_23.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db020b-2f19-4c89-8ee5-45bb2810c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "Q2_2023 = Q2_23[['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']]\n",
    "\n",
    "# renaming columns\n",
    "Q2_2023 = Q2_2023.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 1': 'Apr 2023', \n",
    "                                'Unnamed: 2': 'May 2023', \n",
    "                                'Unnamed: 3': 'Jun 2023'\n",
    "                               })\n",
    "\n",
    "# drop rows with missing values \n",
    "Q2_2023 = Q2_2023.dropna(subset=['ZipCode', 'Apr 2023', 'May 2023', 'Jun 2023'], how='all')\n",
    "\n",
    "# drop unnecessary rows\n",
    "Q2_2023 = Q2_2023.drop([1, 3, 4, 5])\n",
    "\n",
    "#  remove row where ZipCode column has 'Grand Total'                       \n",
    "Q2_2023 = Q2_2023[Q2_2023['ZipCode'] != 'Grand Total']\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Apr 2023', 'May 2023', 'Jun 2023']:\n",
    "    Q2_2023[month] = Q2_2023[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totalsQ2_23 = Q2_2023[['Apr 2023', 'May 2023', 'Jun 2023']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totalsQ2_23.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code\n",
    "\n",
    "# converting to string\n",
    "totalsQ2_23['Date'] = totalsQ2_23['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totalsQ2_23['month'] = totalsQ2_23['Date'].apply(get_month_MY)\n",
    "totalsQ2_23['year'] = totalsQ2_23['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totalsQ2_23 = totalsQ2_23[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totalsQ2_23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305f9d4-fbee-496d-aa36-38e819e5b92c",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2023: July to September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c43bb8-6429-4ece-80a4-4e705cb020d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# Q3_23.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a49ed82-7d02-45e9-8386-ab6e74b7e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "Q3_2023 = Q3_23[['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']]\n",
    "\n",
    "# renaming columns\n",
    "Q3_2023 = Q3_2023.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 1': 'Jul 2023', \n",
    "                                'Unnamed: 2': 'Aug 2023', \n",
    "                                'Unnamed: 3': 'Sep 2023'\n",
    "                               })\n",
    "\n",
    "# drop rows with missing values \n",
    "Q3_2023 = Q3_2023.dropna(subset=['ZipCode', 'Jul 2023', 'Aug 2023', 'Sep 2023'], how='all')\n",
    "\n",
    "# drop unnecessary rows\n",
    "Q3_2023 = Q3_2023.drop([1, 3, 4])\n",
    "\n",
    "#  remove row where ZipCode column has 'Grand Total'                       \n",
    "Q3_2023 = Q3_2023[Q3_2023['ZipCode'] != 'Grand Total']\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Jul 2023', 'Aug 2023', 'Sep 2023']:\n",
    "    Q3_2023[month] = Q3_2023[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totalsQ3_23 = Q3_2023[['Jul 2023', 'Aug 2023', 'Sep 2023']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totalsQ3_23.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code\n",
    "\n",
    "# converting to string\n",
    "totalsQ3_23['Date'] = totalsQ3_23['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totalsQ3_23['month'] = totalsQ3_23['Date'].apply(get_month_MY)\n",
    "totalsQ3_23['year'] = totalsQ3_23['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totalsQ3_23 = totalsQ3_23[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totalsQ3_23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5764fb-7f71-44ce-82b4-9a3a1074ab3a",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2023: October to December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597328f3-6d16-430f-ae54-f6bc55134279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# Q4_23.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83aab40-e958-44d8-b952-3fc384230cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "Q4_2023 = Q4_23[['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']]\n",
    "\n",
    "# renaming columns\n",
    "Q4_2023 = Q4_2023.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 1': 'Oct 2023', \n",
    "                                'Unnamed: 2': 'Nov 2023', \n",
    "                                'Unnamed: 3': 'Dec 2023'\n",
    "                               })\n",
    "\n",
    "# drop rows with missing values \n",
    "Q4_2023 = Q4_2023.dropna(subset=['ZipCode', 'Oct 2023', 'Nov 2023', 'Dec 2023'], how='all')\n",
    "\n",
    "# drop unnecessary rows\n",
    "Q4_2023 = Q4_2023.drop([1, 3, 4])\n",
    "\n",
    "#  remove row where ZipCode column has 'Grand Total'                       \n",
    "Q4_2023 = Q4_2023[Q4_2023['ZipCode'] != 'Grand Total']\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Oct 2023', 'Nov 2023', 'Dec 2023']:\n",
    "    Q4_2023[month] = Q4_2023[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totalsQ4_23 = Q4_2023[['Oct 2023', 'Nov 2023', 'Dec 2023']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totalsQ4_23.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code\n",
    "\n",
    "# converting to string\n",
    "totalsQ4_23['Date'] = totalsQ4_23['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totalsQ4_23['month'] = totalsQ4_23['Date'].apply(get_month_MY)\n",
    "totalsQ4_23['year'] = totalsQ4_23['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totalsQ4_23 = totalsQ4_23[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totalsQ4_23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98594bf-dba0-413f-8a8e-42f7493a0227",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2024: January to March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77426d5c-18e3-4d35-9790-865ac06b6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# Q1_24.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41a493-58c8-43f6-9a2b-d81d3521a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "Q1_2024 = Q1_24[['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']]\n",
    "\n",
    "# renaming columns\n",
    "Q1_2024 = Q1_2024.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 1': 'Jan 2024', \n",
    "                                'Unnamed: 2': 'Feb 2024', \n",
    "                                'Unnamed: 3': 'Mar 2024'\n",
    "                               })\n",
    "\n",
    "# drop rows with missing values \n",
    "Q1_2024 = Q1_2024.dropna(subset=['ZipCode', 'Jan 2024', 'Feb 2024', 'Mar 2024'], how='all')\n",
    "\n",
    "# drop unnecessary rows\n",
    "Q1_2024 = Q1_2024.drop([1, 3, 4])\n",
    "\n",
    "#  remove row where ZipCode column has 'Grand Total'                       \n",
    "Q1_2024 = Q1_2024[Q1_2024['ZipCode'] != 'Grand Total']\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Jan 2024', 'Feb 2024', 'Mar 2024']:\n",
    "    Q1_2024[month] = Q1_2024[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totalsQ1_24 = Q1_2024[['Jan 2024', 'Feb 2024', 'Mar 2024']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totalsQ1_24.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code \n",
    "\n",
    "# converting to string\n",
    "totalsQ1_24['Date'] = totalsQ1_24['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totalsQ1_24['month'] = totalsQ1_24['Date'].apply(get_month_MY)\n",
    "totalsQ1_24['year'] = totalsQ1_24['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totalsQ1_24 = totalsQ1_24[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totalsQ1_24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc56e7-67fe-40f3-952f-df3d16b0d8f9",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2024: March to April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa6a93-d1e6-44b0-a28b-926eff5d5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# Q2_24.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd62cf1-e3cb-49d4-9cc5-6255186cc2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "Q2_2024 = Q2_24[['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']]\n",
    "\n",
    "# renaming columns\n",
    "Q2_2024 = Q2_2024.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 1': 'Apr 2024', \n",
    "                                'Unnamed: 2': 'May 2024', \n",
    "                                'Unnamed: 3': 'Jun 2024'\n",
    "                               })\n",
    "\n",
    "# drop rows with missing values \n",
    "Q2_2024 = Q2_2024.dropna(subset=['ZipCode', 'Apr 2024', 'May 2024', 'Jun 2024'], how='all')\n",
    "\n",
    "# drop unnecessary rows\n",
    "Q2_2024 = Q2_2024.drop([1, 3, 4])\n",
    "\n",
    "#  remove row where ZipCode column has 'Grand Total'                       \n",
    "Q2_2024 = Q2_2024[Q2_2024['ZipCode'] != 'Grand Total']\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Apr 2024', 'May 2024', 'Jun 2024']:\n",
    "    Q2_2024[month] = Q2_2024[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totalsQ2_24 = Q2_2024[['Apr 2024', 'May 2024', 'Jun 2024']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totalsQ2_24.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code \n",
    "\n",
    "# converting to string\n",
    "totalsQ2_24['Date'] = totalsQ2_24['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totalsQ2_24['month'] = totalsQ2_24['Date'].apply(get_month_MY)\n",
    "totalsQ2_24['year'] = totalsQ2_24['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totalsQ2_24 = totalsQ2_24[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totalsQ2_24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad327310-a2c0-4f98-ae95-d3376bd587b1",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2024: July to September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9c0d8-2cea-493c-b38f-5015f77b64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# Q3_24.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c3579-6705-4fbe-bc23-534417e7e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "Q3_2024 = Q3_24[['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']]\n",
    "\n",
    "# renaming columns\n",
    "Q3_2024 = Q3_2024.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 1': 'Jul 2024', \n",
    "                                'Unnamed: 2': 'Aug 2024', \n",
    "                                'Unnamed: 3': 'Sep 2024'\n",
    "                               })\n",
    "\n",
    "# drop rows with missing values \n",
    "Q3_2024 = Q3_2024.dropna(subset=['ZipCode', 'Jul 2024', 'Aug 2024', 'Sep 2024'], how='all')\n",
    "\n",
    "# drop unnecessary rows\n",
    "Q3_2024 = Q3_2024.drop([1, 3, 4])\n",
    "\n",
    "#  remove row where ZipCode column has 'Grand Total'                       \n",
    "Q3_2024 = Q3_2024[Q3_2024['ZipCode'] != 'Grand Total']\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Jul 2024', 'Aug 2024', 'Sep 2024']:\n",
    "    Q3_2024[month] = Q3_2024[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totalsQ3_24 = Q3_2024[['Jul 2024', 'Aug 2024', 'Sep 2024']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totalsQ3_24.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code\n",
    "\n",
    "# converting to string\n",
    "totalsQ3_24['Date'] = totalsQ3_24['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totalsQ3_24['month'] = totalsQ3_24['Date'].apply(get_month_MY)\n",
    "totalsQ3_24['year'] = totalsQ3_24['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totalsQ3_24 = totalsQ3_24[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totalsQ3_24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3108346-4ada-4cd7-8db8-8da1dbe5ec23",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CalFresh Allotments from 2024: October to December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc7f45-fe1b-4a90-a64c-06362324c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the structure and content of the dataset\n",
    "# Q4_24.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed01110-730a-4e4b-a43b-b37823cf2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df with necessary columns\n",
    "Q4_2024 = Q4_24[['Unnamed: 0', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6']]\n",
    "\n",
    "# renaming columns\n",
    "Q4_2024 = Q4_2024.rename(columns=\n",
    "                               {'Unnamed: 0': 'ZipCode', \n",
    "                                'Unnamed: 4': 'Oct 2024', \n",
    "                                'Unnamed: 5': 'Nov 2024', \n",
    "                                'Unnamed: 6': 'Dec 2024'\n",
    "                               })\n",
    "\n",
    "# drop rows with missing values \n",
    "Q4_2024 = Q4_2024.dropna(subset=['ZipCode', 'Oct 2024', 'Nov 2024', 'Dec 2024'], how='all')\n",
    "\n",
    "# drop unnecessary rows\n",
    "Q4_2024 = Q4_2024.drop([1, 3, 4])\n",
    "\n",
    "#  remove row where ZipCode column has 'Grand Total'                       \n",
    "Q4_2024 = Q4_2024[Q4_2024['ZipCode'] != 'Grand Total']\n",
    "\n",
    "# Remove dollar signs $ and commas and convert to a float\n",
    "for month in ['Oct 2024', 'Nov 2024', 'Dec 2024']:\n",
    "    Q4_2024[month] = Q4_2024[month].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "# sum all the rows for each column and reset index\n",
    "totalsQ4_24 = Q4_2024[['Oct 2024', 'Nov 2024', 'Dec 2024']].sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "totalsQ4_24.columns = ['Date', 'CountyTotal']\n",
    "\n",
    "# adding in a month and year column using code\n",
    "\n",
    "# converting to string\n",
    "totalsQ4_24['Date'] = totalsQ4_24['Date'].astype(str)\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "totalsQ4_24['month'] = totalsQ4_24['Date'].apply(get_month_MY)\n",
    "totalsQ4_24['year'] = totalsQ4_24['Date'].apply(get_year_MY)\n",
    "\n",
    "# Dropping Date column\n",
    "totalsQ4_24 = totalsQ4_24[['month', 'year', 'CountyTotal']]\n",
    "\n",
    "totalsQ4_24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132ec86-03a9-4e67-b1cc-5f420bd2f313",
   "metadata": {},
   "source": [
    "---\n",
    "### Merging and Concatenating Datasets Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b544ab1c-a93a-4bc2-bf84-0157ecb76054",
   "metadata": {},
   "source": [
    "We proceed to merge together all cleaned county datasets to create a new dataset with the sum total of all zip issuances. This new dataset is stored in `totals22_24`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e010b-e5d5-4b93-b6cc-9e05d0b88cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging all dfs together\n",
    "totals22_24 = pd.concat([totals_jan_may22, \n",
    "                         totals_june22, \n",
    "                         totalsQ3_22,\n",
    "                         totalsQ4_22,\n",
    "                         totalsQ1_23,\n",
    "                         totalsQ2_23,\n",
    "                         totalsQ3_23,\n",
    "                         totalsQ4_23,\n",
    "                         totalsQ1_24,\n",
    "                         totalsQ2_24,\n",
    "                         totalsQ3_24,\n",
    "                         totalsQ4_24\n",
    "                        ],ignore_index=True)\n",
    "\n",
    "# Creating a datetime column to plot easier\n",
    "totals22_24 = totals22_24.copy()\n",
    "\n",
    "# creating a datetime column (these should all be unique values if there are no duplicates in the dataframe)\n",
    "totals22_24['Date'] = pd.to_datetime(totals22_24[['year', 'month']].assign(day=1))\n",
    "\n",
    "# Sort by date in ascending order\n",
    "totals22_24 = totals22_24.sort_values(by='Date')\n",
    "totals22_24.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a73a6-da54-473a-a2e6-4beac08205c8",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2 Visualizing Total CalFresh Allotments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2786ac-3d5f-49ba-9170-432caced9c62",
   "metadata": {},
   "source": [
    "Following data wrangling, we can visualize the total CalFresh allotments. The line plot below depicts monthly CalFresh allotments starting from 2022 to 2024. The x-axis represents time while the y-axis represents the total *$* amount allloted in millions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d569d-1f93-4222-8ab5-9f960ed313be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to Amy for code block\n",
    "\n",
    "# Creating a line plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.lineplot(x='Date', y='CountyTotal', data= totals22_24, marker='o')\n",
    "ax.set_title('Calfresh Allotments by Months')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Calfresh Allotments (in millions)')\n",
    "\n",
    "# Uncomment line below for y-axis in millions\n",
    "#ax.ticklabel_format(style='plain', axis='y')  \n",
    "\n",
    "# Setting respective years on x-axis\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month=7, day = 15))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "ax.tick_params(axis='x', which='major', pad=25) # space between years and months\n",
    "\n",
    "# Setting respective months on x-axis\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())  \n",
    "ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b')) \n",
    "\n",
    "\n",
    "sns.despine() \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ddc356-bdb4-4170-a48a-93c02ba4256d",
   "metadata": {},
   "source": [
    "When observing the plotted data there is a steady upward trend from 2022 to 2024. However, there are sudden spikes and drops, such as in September 2022, that reflect approved emergency allotments for that month. Despite these sudden spikes the data looks relatively stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361362b-b2d8-4bcb-815b-0a13038a3c86",
   "metadata": {},
   "source": [
    "Observed CalFresh Emergency Allotment Months:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b014da2-b329-4517-8a02-1691427da528",
   "metadata": {},
   "source": [
    "* Food Benefits Available for People Impacted by **Late January 2024 Storms**: \"On March 1, 2024, the United States Department of Agriculture approved California’s request for Disaster CalFresh food benefits to enhance recovery efforts in San Diego County. The program is known nationally as the Disaster Supplemental Nutrition Assistance Program, or D-SNAP\" (*Cal OES News*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44155724-dd5e-42b5-9995-a7380ed88060",
   "metadata": {},
   "source": [
    "* **COVID-19 CalFresh emergency allotment for August, 2022**: \"California has been approved to issue an emergency allotment of CalFresh for August, 2022.  All households will receive at least the maximum CalFresh allotment. The emergency allotment will be issued on September 4, 2022 for CalSAWS counties and September 10, 2022 for CalWIN counties. Additional allotments were approved in September and issued October 16th, 2022\" (*Legal Services of Northern California*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a025c55-c6d1-436d-ac1a-44959294ccc4",
   "metadata": {},
   "source": [
    "Termination of Covid-19 Emergency Allotments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f975887b-2b88-4d11-8ca9-b1f38dc850b6",
   "metadata": {},
   "source": [
    "* **Covid-19 Emergency Allotments ended in February 2023**, with the last amounts being  issued in March 2023. April will be the first month benefit holders will see a decrease in the amount of CalFresh benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8fa74-4f70-40e7-b049-573f7bf09668",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e14a1-c716-4e1c-9381-b7bd509fa632",
   "metadata": {},
   "source": [
    "We begin by generating a predictive models to examine the relationship between total CalFresh allotments and a specific month in the year. \n",
    "\n",
    "The first approach we take is a multiple linear regression to understand whether the observed drops and spikes in the data have an impact on model performance. \n",
    "\n",
    "The formula that takes the form of the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b6151-fd9a-43b6-839f-700df05e0dd0",
   "metadata": {},
   "source": [
    "$${CountyTotal} = \\beta_0+ \\beta_1*{Month}+ \\beta_2*{Year}+\\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9122a3e2-afc7-4784-9c5a-680c92b0426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using multiple linear regression model to estimate CalFresh dollars issued (CountyTotal) dependent on the month and year.\n",
    "model = smf.ols(data=totals22_24, formula=\"CountyTotal ~ month + year\").fit()\n",
    "\n",
    "# Summary table of our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ca6f5-7ed5-418a-bf96-291a84afd984",
   "metadata": {},
   "source": [
    "When looking at model performance the model is statistically significant, with an adjusted R-squared of 0.84. Additionally, both month and year have a small p-value which confirms that we do see a gradual incresse in CalFresh allotments over time. However, we take into account the Durbin-Watson statistic, at 0.668, which suggests that the model is overlooking the spikes/drops in the data leading to autocorrelation. This leads us to incorporate dummy variables to account for these fluctuations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683764ba-e070-401d-ba04-5d3a12f20db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at model parameters\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a14f215-a1fe-48e3-96ef-1e1efb894c7c",
   "metadata": {},
   "source": [
    "The model predicts the following:\n",
    "\n",
    "* For every month, CalFresh allotments go up by $689,900.\n",
    "  \n",
    "* For every year, CalFresh allotments go up by $6.47 million."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799765f9-5efe-4ae6-afab-6ae11528e0de",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating Dummy Variables for Emergency Allotments and end of Covid Emergency Allotments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0149778-4a1c-4c9e-89d0-843eb09b5483",
   "metadata": {},
   "source": [
    "We set `emergency_allotments` to 0 for the portion of the data that does not have an approval to issue an emergency allotment, we set `emergency_allotments` to 1 for the presence of an approval for an emergency allotment.\n",
    "\n",
    "We set `covid_end` to 0 for the portion of the data that was not in the time period of the end of federal pandemic aid programs, we set `covid_end` to 1 for months that saw a decrease in CalFresh allotments from the end of federal pandemic aid programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a972a6-39ac-4af1-bdd0-cfd56b817511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the index for months that had an approval for an emergency allotment\n",
    "emergency_allotments = ['2022-09-01', '2024-03-01']\n",
    "\n",
    "# turning into a datetime column\n",
    "emergency_allotments = pd.to_datetime(emergency_allotments)\n",
    "\n",
    "# setting the index\n",
    "totals22_24['emergency_allotments'] = totals22_24['Date'].isin(emergency_allotments).astype(int)\n",
    "\n",
    "\n",
    "# creating the index for months that had COVID emergency allotments end\n",
    "covid_end = ['2023-04-01']\n",
    "\n",
    "# turning into a datetime column\n",
    "covid_end = pd.to_datetime(covid_end)\n",
    "\n",
    "# setting the index\n",
    "totals22_24['covid_end'] = totals22_24['Date'].isin(covid_end).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dae872-14af-4446-86da-d8592766f06d",
   "metadata": {},
   "source": [
    "---\n",
    "### Predictive Modeling with Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aee3ea-12e1-4f43-b648-8c1eb34aa674",
   "metadata": {},
   "source": [
    "Now, we generate a multiple linear regression model that accounts for the spikes and drops in the data set. We include the new dummy variables, `emergency_allotments` and `covid_end`, to expand the model.\n",
    "\n",
    "The formula now takes the form of the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b3297-f877-4838-bd41-778bd0548077",
   "metadata": {},
   "source": [
    "$${CountyTotal} = \\beta_0+ \\beta_1*{Month}+ \\beta_2*{Year}+ \\beta_3*{EmergencyAllotments}+ \\beta_4*{CovidEnd}+\\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c5f36-8630-4b4c-b755-225f2e78c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(data=totals22_24, formula=\"CountyTotal ~ month + year + emergency_allotments + covid_end \").fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a922eb-59df-46cc-8d06-de4854439ff7",
   "metadata": {},
   "source": [
    "The expanded model shows an overall improved performance compared to the first model, with an adjusted R-squared of 0.864. What stands out in the results is the significance of the dummy variables, `emergency_allotments` and `covid_end`. `emergency_allotments` is statistically significant at p = 0.01, `covid_end` however is not statistically significant sitting at p = 0.688. This suggests that the drop in the data set is not large enough to be considered an outlier.\n",
    "\n",
    "Despite the improvement in the model, we still see the Durbin-Watson score at 0.615, suggesting that the model continues to have a postive autocorrelation. This result overall leads us to come to the conclusion that the model may do best in predicting long term growth but not capture these small spikes and drops present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08efa9b1-2117-438e-b4e2-5fc4f9c8fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5ec59-1e7a-4621-8ad5-31390634c2fd",
   "metadata": {},
   "source": [
    "Looking at `emergency _allotments`, the model has predicted an increase in allotments of ~ $4.71m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d995e2e-3a0b-4bc5-bd2b-33206aa049f7",
   "metadata": {},
   "source": [
    "---\n",
    "### Plotting Predicted v. Actual CalFresh Allotments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a9423a-663a-4fc1-abfd-ccbbaad22819",
   "metadata": {},
   "source": [
    "The line plot depicts monthly predicted CalFresh allotments from the multiple linear regression with dummy variables v. the actual CalFresh allotments starting from 2022 to 2024. The x-axis represents time while the y-axis represents the total *$* amount alloted in millions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ddea3-9da7-45ac-b947-bb51710fb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted dependent variable (predictions)\n",
    "totals22_24_copy = totals22_24.copy()\n",
    "totals22_24_copy['yhat'] = model.fittedvalues\n",
    "\n",
    "# Creating a line plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(totals22_24_copy['Date'],totals22_24_copy['CountyTotal'],label =\"Actual Calfresh Allotments\", marker='o')\n",
    "plt.plot(totals22_24_copy['Date'],totals22_24_copy['yhat'],label=\"Predicted Calfresh Allotments\",linestyle='--')\n",
    "\n",
    "# higlighting dummy months: emergency allotments\n",
    "emergency_only = totals22_24_copy[totals22_24_copy['emergency_allotments'] == 1]\n",
    "\n",
    "plt.scatter(emergency_only['Date'], emergency_only['CountyTotal'],\n",
    "            color='red', label='Emergency Allotments', zorder=3)\n",
    "\n",
    "# higlighting dummy months: end of covid-19 emergency allotments\n",
    "covid_only = totals22_24_copy[totals22_24_copy['covid_end'] == 1]\n",
    "\n",
    "plt.scatter(covid_only['Date'], covid_only['CountyTotal'],\n",
    "            color='purple', label='COVID Emergency End', zorder=3)\n",
    "\n",
    "\n",
    "plt.title('Calfresh Allotments by Months with Predicted Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Calfresh Allotments (in millions)')\n",
    "legend=plt.legend()\n",
    "\n",
    "sns.despine() \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b5a35d-857c-4324-95d8-8fa0ebfd5376",
   "metadata": {},
   "source": [
    "When observing the plotted predicted values the model does well in capturing the upward trend, and the spikes from the months with emergency allotments. However, it does not capture the small flucations across the months which reflects on the capacity of a multiple linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a35c347-621a-4349-ac98-80d2db57d150",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.4 Multiple Linear Regression Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dbc4d2-a684-4af2-bb71-c01f18f6a754",
   "metadata": {},
   "source": [
    "Below we proceeded with using the model to predict the *$* issued in CalFresh benefits for each month, starting with the first quarter of 2025, assuming no emergency allotments or drops in benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb00c7-3fc0-47f6-8af2-350baa6acfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new DataFrame with the first quarter of 2025 (Jan - Mar)\n",
    "df_new = pd.DataFrame({'month': [1,2,3], \n",
    "                       'year': [2025, 2025, 2025],\n",
    "                      'emergency_allotments': [0, 0, 0],#assuming no emergency allotments\n",
    "                       'covid_end': [0, 0, 0]#assuming no drops in benefits\n",
    "                      })\n",
    "\n",
    "print(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e7d57-7cf5-4f40-9602-07e850bfc4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict scores for the next 3 months (Jan-Mar 2025)\n",
    "model.predict(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb3dec2-fec0-4b35-a677-0e6c235d05a0",
   "metadata": {},
   "source": [
    "The model predicts monthly increases of around $700k per month, which is consistent with the results of the regression above. \n",
    "\n",
    "* January 2025 = $76,410,250\n",
    "  \n",
    "* February 2025 = $77,116,800\n",
    "  \n",
    "* March 2025  = $77,823,350"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0af7fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Predicting Total School Meals\n",
    "\n",
    "In this next section, we explore options to predict total school meals provided. As previous notes, SDHC currently operates on a 4 month time lag to provide insight on the meal gap - school meal data contributes greatly to this delay. Thus, we aim to build the foundations for an accurate model to predict school meal data on a monthly basis to allow SDHC to work and report on a smaller time lag.\n",
    "\n",
    "## 4.1 Data Cleaning/Wrangling\n",
    "\n",
    "Currently, the data available to us includes school meal data from July 2021 - March 2022, spread across three different dataframes (`CACFP_2122`, `SFSP_21`, and `SNP_2122`) and school meal data from January 2021 - June 2021, April 2022 - September 2024 (`school_meal_incomplete`). Prior to any modeling exploration, we must clean all our datasets and merge them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Imports \n",
    "# uncomment below and run if installation is needed (Juypter Notebook)\n",
    "# !pip install pandas scikit-learn statsmodels numpy matplotlib seaborn scipy piecewise-regression pwlf\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from scipy.fft import dct, idct\n",
    "import piecewise_regression\n",
    "import pwlf\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "54beb267",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/school_meals/CACFP_July21March22.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load in datasets, provided by California Department of Education, Nutrition Services Division\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# CACFP (July 2021 to March 2022) - Retrieved on June 15, 2022 \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m CACFP_2122 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/school_meals/CACFP_July21March22.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# SFSP July to August 2021 (no Sept 2021 to Mar 2022 data) - Retrieved on June 15, 2022 \u001b[39;00m\n\u001b[1;32m      7\u001b[0m SFSP_21 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/school_meals/SFSP_JulyAug_2021.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/school_meals/CACFP_July21March22.csv'"
     ]
    }
   ],
   "source": [
    "# load in datasets, provided by California Department of Education, Nutrition Services Division\n",
    "\n",
    "# CACFP (July 2021 to March 2022) - Retrieved on June 15, 2022 \n",
    "CACFP_2122 = pd.read_csv('data/school_meals/CACFP_July21March22.csv')\n",
    "\n",
    "# SFSP July to August 2021 (no Sept 2021 to Mar 2022 data) - Retrieved on June 15, 2022 \n",
    "SFSP_21 = pd.read_csv('data/school_meals/SFSP_JulyAug_2021.csv')\n",
    "\n",
    "# SNP (July 2021 to March 2022) - Retrieved on June 15, 2022 \n",
    "SNP_2122 = pd.read_csv('data/school_meals/SNP_July21March22.csv')\n",
    "\n",
    "# SDHC School Meal Data \n",
    "school_meal_incomplete = pd.read_csv('data/school_meals/school_meals_incomplete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e087c8",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling CACFP_2122 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only saving relevant columns \n",
    "CACFP_2122 = CACFP_2122[['FnsReportDate','MealTypeCode','DaysServedQty',' SumOfMlsServedTotal ']]\n",
    "\n",
    "# Clean out whitespace in column names and lowercase \n",
    "CACFP_2122.rename(columns={c: c.strip().lower() for c in CACFP_2122.columns.tolist()}, inplace=True)\n",
    "\n",
    "# Change sumofmlsservedtotal from object to int\n",
    "CACFP_2122['sumofmlsservedtotal'] = (CACFP_2122['sumofmlsservedtotal']\n",
    "    .astype(str)           # Convert to string\n",
    "    .str.replace(',', '')  # Remove commas\n",
    "    .str.strip()           # Remove any surrounding whitespace\n",
    "    .astype(int)           # Convert to integer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad86c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking unique mealtypecodes \n",
    "cacp_mealtypes = CACFP_2122['mealtypecode'].unique()\n",
    "\n",
    "# removing rows with snacks\n",
    "CACFP_2122 = CACFP_2122[~CACFP_2122['mealtypecode'].str.contains('SNACK')]\n",
    "\n",
    "# grouping by fnsreportdate to get the full sum of mlsservedtotal\n",
    "CACFP_2122 = CACFP_2122.groupby(['fnsreportdate']).sum()[['sumofmlsservedtotal']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b636306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding in a month and year column using fnsreportdate information\n",
    "\n",
    "# Applying both functions and creating new columns \n",
    "CACFP_2122['month'] = CACFP_2122['fnsreportdate'].apply(get_month_MY)\n",
    "CACFP_2122['year'] = CACFP_2122['fnsreportdate'].apply(get_year_MY)\n",
    "\n",
    "# Dropping fnsreportdate column\n",
    "CACFP_2122 = CACFP_2122[['month', 'year', 'sumofmlsservedtotal']]\n",
    "\n",
    "# Renaming sumofmlsservedtotal for merging later\n",
    "CACFP_2122 = CACFP_2122.rename(columns= {'sumofmlsservedtotal': 'cacptotal'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ea315",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACFP_2122.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9316a1b",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling SFSP_21 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afddf10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only saving relevant columns \n",
    "SFSP_21 = SFSP_21[['ClaimDate','MealTypeCode','DaysServedQty','MlsServedFree']]\n",
    "\n",
    "# Clean out whitespace in column names and lowercase \n",
    "SFSP_21.rename(columns={c: c.strip().lower() for c in SFSP_21.columns.tolist()}, inplace=True)\n",
    "\n",
    "# Change sumofmlsservedtotal from object to int\n",
    "SFSP_21['mlsservedfree'] = (SFSP_21['mlsservedfree']\n",
    "    .astype(str)           # Convert to string\n",
    "    .str.replace(',', '')  # Remove commas\n",
    "    .str.strip()           # Remove any surrounding whitespace\n",
    "    .astype(int)           # Convert to integer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffc377",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFSP_21.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking unique mealtypecodes \n",
    "sfsp_mealtypes = SFSP_21['mealtypecode'].unique()\n",
    "\n",
    "# removing rows with snacks\n",
    "SFSP_21 = SFSP_21[~SFSP_21['mealtypecode'].str.contains('SNACK')]\n",
    "\n",
    "# grouping by claimdate to get the full sum of mlsservedfree\n",
    "SFSP_21 = SFSP_21.groupby(['claimdate']).sum()[['mlsservedfree']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3fc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding in a month and year column using claimdate information\n",
    "\n",
    "# applying functions to claimdate column\n",
    "SFSP_21['month'] = SFSP_21['claimdate'].apply(get_month_MDY)\n",
    "SFSP_21['year'] = SFSP_21['claimdate'].apply(get_year_MDY)\n",
    "\n",
    "# Dropping fnsreportdate column\n",
    "SFSP_21 = SFSP_21[['month', 'year', 'mlsservedfree']]\n",
    "\n",
    "# Renaming sumofmlsservedtotal for merging later\n",
    "SFSP_21 = SFSP_21.rename(columns= {'mlsservedfree': 'sfsptotal'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd39971",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFSP_21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529814b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Wrangling SNP_2122 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only saving relevant columns \n",
    "SNP_2122 = SNP_2122[['ClaimDate','MealTypeCode','DaysServedQty',' MlsServedTotal ']]\n",
    "\n",
    "# Clean out whitespace in column names and lowercase \n",
    "SNP_2122.rename(columns={c: c.strip().lower() for c in SNP_2122.columns.tolist()}, inplace=True)\n",
    "\n",
    "# Change mlsservedtotal from object to int\n",
    "SNP_2122['mlsservedtotal'] = (SNP_2122['mlsservedtotal']\n",
    "    .astype(str)           # Convert to string\n",
    "    .str.replace(',', '')  # Remove commas\n",
    "    .str.strip()           # Remove any surrounding whitespace\n",
    "    .astype(int)           # Convert to integer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652be91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP_2122.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c633c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking unique mealtypecodes \n",
    "snp_mealtypes = SNP_2122['mealtypecode'].unique()\n",
    "\n",
    "# removing rows with snacks\n",
    "SNP_2122 = SNP_2122[~SNP_2122['mealtypecode'].str.contains('SNACK')]\n",
    "\n",
    "# grouping by claimdate to get the full sum of mlsservedfree\n",
    "SNP_2122 = SNP_2122.groupby(['claimdate']).sum()[['mlsservedtotal']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936290f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding in a month and year column using claimdate information\n",
    "\n",
    "# applying functions to claimdate column\n",
    "SNP_2122['month'] = SNP_2122['claimdate'].apply(get_month_MDY)\n",
    "SNP_2122['year'] = SNP_2122['claimdate'].apply(get_year_MDY)\n",
    "\n",
    "# Dropping fnsreportdate column\n",
    "SNP_2122 = SNP_2122[['month', 'year', 'mlsservedtotal']]\n",
    "\n",
    "# Renaming sumofmlsservedtotal for merging later\n",
    "SNP_2122 = SNP_2122.rename(columns= {'mlsservedtotal': 'snptotal'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8393bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP_2122.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1ec88",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrangling SDHC School Meal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdf070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out whitespace in column names and lowercase \n",
    "school_meal_incomplete.rename(columns={c: c.strip().lower().replace(\" \", \"\") for c in school_meal_incomplete.columns.tolist()}, inplace=True)\n",
    "\n",
    "# Change sumofmlsservedtotal from object to int\n",
    "school_meal_incomplete['totalschoolmeals'] = (school_meal_incomplete['totalschoolmeals']\n",
    "    .astype(str)           # Convert to string\n",
    "    .str.replace(',', '')  # Remove commas\n",
    "    .str.strip()           # Remove any surrounding whitespace\n",
    "    .astype(int)           # Convert to integer\n",
    ")\n",
    "# Replace '-' with ' ' in month column so get_month_MY and get_year_MYcan be applied\n",
    "school_meal_incomplete['date'] = school_meal_incomplete['month'].str.replace('-', ' ')\n",
    "school_meal_incomplete['month'] = school_meal_incomplete['date'].apply(get_month_MY)\n",
    "school_meal_incomplete['year'] = school_meal_incomplete['date'].apply(get_year_MY) + 2000\n",
    "\n",
    "school_meal_incomplete = school_meal_incomplete[['month', 'year', 'totalschoolmeals']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_meal_incomplete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab6912",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Merging and Concatentating Datasets Together\n",
    "\n",
    "With all datasets cleaned, we can merge together then CACFP_2122, SFSP_21, and SNP_2122 data and sum each of their respective totals to get all the school meals provided in a given month. The resulting dataset is stored in `jul21_mar22`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dadf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging CACFP_2122 and SNP_2122 df together\n",
    "CACFP_2122_SNP_2122 = pd.merge(CACFP_2122, SNP_2122, left_on=['month', 'year'], right_on=['month', 'year'], how='inner')\n",
    "\n",
    "# merging SFSP_21 data with CACFP_2122_SNP_2122\n",
    "jul21_mar22 = pd.merge(CACFP_2122_SNP_2122, SFSP_21, left_on=['month', 'year'], right_on=['month', 'year'], how='left')\n",
    "\n",
    "# replacing NaN values in sfsptotal column with 0\n",
    "jul21_mar22['sfsptotal'] = jul21_mar22['sfsptotal'].fillna(0)\n",
    "\n",
    "# creating a new column 'totalschoolmeals' by summing cacptoal, snptotal, and sfsptotal\n",
    "jul21_mar22['totalschoolmeals'] = jul21_mar22['cacptotal'] + jul21_mar22['snptotal'] + jul21_mar22['sfsptotal']\n",
    "\n",
    "# subsetting month, year, and totalschoolmeals\n",
    "jul21_mar22 = jul21_mar22[['month', 'year', 'totalschoolmeals']]\n",
    "\n",
    "# dropping repeats for concatentation\n",
    "jul21_mar22 = jul21_mar22[jul21_mar22['month'] > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed807888",
   "metadata": {},
   "source": [
    "The data can now be combined with the rest of SDHC's data on school meals. The resulting dataframe is stored in `school_meals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f51048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine July 2021 - March 2022 data with the rest of SDHC's school meal data\n",
    "school_meals = pd.concat([jul21_mar22, school_meal_incomplete], axis=0, ignore_index=True)\n",
    "\n",
    "# Adding remaining 2024 data (received 4/10/25)\n",
    "new_rows = pd.DataFrame({\n",
    "    \"month\": [10, 11, 12],\n",
    "    \"year\": [2024, 2024, 2024],\n",
    "    'totalschoolmeals': [8900526, 6354103, 6123894]\n",
    "    })\n",
    "\n",
    "school_meals = pd.concat([school_meals, new_rows], ignore_index=True)\n",
    "\n",
    "# Sort by date in ascending order\n",
    "school_meals.sort_values(by=['year', 'month'], ascending=[True, True], inplace=True)\n",
    "school_meals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b084012b",
   "metadata": {},
   "source": [
    "We also initiate a check for any duplicate values for a given month. If there are no duplicates, the cell below should output `True`. With no duplicates, we export the cleaned dataframe to a .csv file for ease of future use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6ac69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Double check for duplicates values - if there are no duplicates, cell output should be True (boolean)\n",
    "\n",
    "# creating a copy of wrangled school_meals dataframe\n",
    "dup_check = school_meals\n",
    "\n",
    "# creating a datetime column (these should all be unique values if there are no duplicates in the dataframe)\n",
    "dup_check['date'] = pd.to_datetime(dup_check[['year', 'month']].assign(day=1))\n",
    "\n",
    "# getting number of unique rows (dates)\n",
    "num_unique = len(dup_check['date'].unique())\n",
    "\n",
    "# comparing number of unique rows to total number of rows (True = no duplicates; False = duplicates)\n",
    "num_unique == len(dup_check['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff23dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Leave commented, exporting cleaned dataframe to .csv file\n",
    "# school_meals.to_csv('school_meals_2021_2024.csv', index=False, sep=',', na_rep='', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b41b81",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 4.2 Visualizing Total School Meals \n",
    "\n",
    "With the cleaned dataframe, we contruct a line plot of school meals over time to visualize the data we have. To do this, we first filter out the two 2020 data points since we don't have the remaining 2020 data, plotting from 2021-2024. The x-axis represents time while the y-axis represents total school meals in millions. The vertical lines on the plot separate and designate each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2053029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out 2020 data (non-continuous)\n",
    "no_2020 = school_meals[school_meals['year']!= 2020]\n",
    "\n",
    "# Creating a datetime column to plot easier\n",
    "no_2020 = no_2020.copy()\n",
    "no_2020['date'] = pd.to_datetime(no_2020[['year', 'month']].assign(day=1))\n",
    "no_2020 = no_2020.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3558c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a line plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "ax = sns.lineplot(x='date', \n",
    "                  y='totalschoolmeals', \n",
    "                  data=no_2020, \n",
    "                  marker='o', \n",
    "                  color = 'gray')\n",
    "ax.set_title('San Diego School Meals Over Time')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('School Meals (in millions)')\n",
    "\n",
    "# Uncomment line below for y-axis in millions\n",
    "#ax.ticklabel_format(style='plain', axis='y')  \n",
    "\n",
    "years = [2021, 2022, 2023, 2024]\n",
    "for y in years:\n",
    "    ax.axvline(pd.Timestamp(f'{y}-01-01'),\n",
    "               color='black',\n",
    "               linestyle='--',\n",
    "               linewidth=1,\n",
    "               alpha=0.5)\n",
    "\n",
    "# Setting respective years on x-axis\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month=7, day = 15))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "ax.tick_params(axis='x', which='major', pad=25) # space between years and months\n",
    "\n",
    "# Setting respective months on x-axis\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())  \n",
    "ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b')) \n",
    "\n",
    "sns.despine() \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a96e5",
   "metadata": {},
   "source": [
    "From the plotted data, it becomes evident that there is a periodic pattern of total school meals in a year. Meals increase starting January, ending in May; from there, they decrease until July and rise until October. Meals decrease from then to the end of the year. While there is variability across each year, this general pattern holds. Keeping the periodicity of the data in mind, we can leverage this to build predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08faa2d0",
   "metadata": {},
   "source": [
    "## 4.3 Ordinal Piecewise Regression\n",
    "Ordinal piecewise regression allows us to quantify a relationship where the independent variable is ordinal, and there may be multiple relationships to examine in our data. The independent variable is segmented by points, and a separate regression line is fit to each interval. This helps us compare, for example, how a variable changes from Fall to Winter, versus how the same variable changes from Spring to Summer.\n",
    "\n",
    "Being able to quantify how the number of total school meals can change across the year, as well as what patterns certain months are characterized by, can inform better predictions. Here, we plot an ordinal piecewise regression line for each year separately, then on top of one another to better display how the relationships differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cbd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data by years: 2022, 2023, 2024 (these are the only years where we have data for all 12 months)\n",
    "\n",
    "# 2021 School meals data\n",
    "school_meals_2021 = school_meals[school_meals['year'] == 2021]\n",
    "\n",
    "# 2022 School meals data\n",
    "school_meals_2022 = school_meals[school_meals['year'] == 2022]\n",
    "\n",
    "# 2023 School meals data\n",
    "school_meals_2023 = school_meals[school_meals['year'] == 2023]\n",
    "\n",
    "# 2024 School meals data\n",
    "school_meals_2024 = school_meals[school_meals['year'] == 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad85ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs = [school_meals_2021, school_meals_2022, school_meals_2023,school_meals_2024]\n",
    "years = ['2021','2022','2023', '2024']\n",
    "\n",
    "betas = []\n",
    "\n",
    "for df, year in zip(dfs, years):\n",
    "    # Fit piecewise model to data\n",
    "    pw_model = pwlf.PiecewiseLinFit(df['month'], df['totalschoolmeals'])\n",
    "\n",
    "    # Fit the data for 6 line segments \n",
    "    res = pw_model.fit(6)\n",
    "\n",
    "    # Predict for the determined points\n",
    "    xHat = np.linspace(min(df['month']), max(df['month']), num=10000)\n",
    "    yHat = pw_model.predict(xHat)\n",
    "    \n",
    "    # Generate parameter values, and store in list betas\n",
    "    betas.append(pw_model.beta)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(8, 4.5))\n",
    "    plt.scatter(df['month'], df['totalschoolmeals'], label=\"Actual Data\", color='#264653')\n",
    "    plt.plot(xHat, yHat, label=\"Piecewise Regression Fit\", color='#9ABD97', linewidth=2)\n",
    "    plt.xlabel(\"Months\")\n",
    "    plt.ylabel(\"Total School Meals\")\n",
    "    plt.title(\"Ordinal Piecewise Regression on School Meals Data - \" + year)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b22ebe",
   "metadata": {},
   "source": [
    "We specified 6 line segments. Therefore, we should be expecting 7 betas, which are the values corresponding to each breakpoint in between the lines. The average value for each breakpoint across the years is displayed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf432f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average of corresponding elements across years\n",
    "averaged_betas = np.mean(betas, axis=0).tolist()\n",
    "averaged_betas\n",
    "\n",
    "# Create table of average breakpoints\n",
    "data_avgbp = {'Breakpoints': [1,2,3,4,5,6,7], 'Values': averaged_betas}\n",
    "df_avgbp = pd.DataFrame(data = data_avgbp)\n",
    "\n",
    "df_avgbp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741e764",
   "metadata": {},
   "source": [
    "However, in averaging the breakpoint values, we lose valuable information about how months can vary year to year. This means we lose the level of granularity in our model that allows us to gain insight into how total school meals differ across time. Here, we plotted the regression lines on top of each other to highlight the different trends from year to year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2463163",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [school_meals_2021, school_meals_2022, school_meals_2023, school_meals_2024]\n",
    "years = ['2021', '2022', '2023', '2024']\n",
    "colors = ['#FA4949', '#FA7E49', '#FFE365', '#43EB64']  # assign different colors for each year\n",
    "\n",
    "betas = []\n",
    "\n",
    "plt.figure(figsize=(10, 5)) \n",
    "\n",
    "for df, year, color in zip(dfs, years, colors):\n",
    "    # Fit piecewise model to data\n",
    "    pw_model = pwlf.PiecewiseLinFit(df['month'], df['totalschoolmeals'])\n",
    "\n",
    "    # Fit the data for X line segments\n",
    "    res = pw_model.fit(6)\n",
    "\n",
    "    # Predict for smooth line\n",
    "    xHat = np.linspace(min(df['month']), max(df['month']), num=10000)\n",
    "    yHat = pw_model.predict(xHat)\n",
    "    \n",
    "    # Save betas\n",
    "    betas.append(pw_model.beta)\n",
    "\n",
    "    # Plot on the same figure\n",
    "    plt.plot(xHat, yHat, label=f\"{year}\", color=color, linewidth=1)\n",
    "\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Total School Meals\")\n",
    "plt.title(\"Ordinal Piecewise Regression on School Meals Data (2021–2024)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d64574",
   "metadata": {},
   "source": [
    "We can also populate a table with the specific values to display how trends in total school meals have differed across years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2e8337b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'betas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m breakpoints \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreakpoint 1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreakpoint 2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreakpoint 3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreakpoint 4\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreakpoint 5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreakpoint 6\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreakpoint 7\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create dataframe\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df_allbps \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(betas,index \u001b[38;5;241m=\u001b[39m years, columns \u001b[38;5;241m=\u001b[39m breakpoints)\n\u001b[1;32m      7\u001b[0m df_allbps\n",
      "\u001b[0;31mNameError\u001b[0m: name 'betas' is not defined"
     ]
    }
   ],
   "source": [
    "# Define breakpoint numbers\n",
    "breakpoints = ['Breakpoint 1', 'Breakpoint 2', 'Breakpoint 3', 'Breakpoint 4','Breakpoint 5','Breakpoint 6','Breakpoint 7']\n",
    "\n",
    "# Create dataframe\n",
    "df_allbps = pd.DataFrame(betas,index = years, columns = breakpoints)\n",
    "\n",
    "df_allbps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358f2dbf",
   "metadata": {},
   "source": [
    "In our plots, the overall trend of the line looks relatively similar from year to year. For example, the first few months are usually characterized with a slow growth, then we see a sharp drop in June and July. However, when we take a look at the breakpoints, it's clear to see that there are significant differences at certain breakpoints across years. In 2021, 2023, and 2024, the number of total school meals increases gradually from January to April. However, in 2022, we see drop in school meals around March, and a quicker increase through April. \n",
    "\n",
    "This highlights how piecewise regression can uncover shifts in trends that aren’t immediately obvious from overall patterns, and allows us to identify year-specific differences - possibly due to external factors like school closures, policy changes, or COVID-related disruptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3566ea8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.4 DCT (Discrete Cosine Transform) Models\n",
    "\n",
    "Another approach we can take if the goal is purely prediction, is a discreate cosine transform (DCT). If we treat the school meal data over a given year as a one-dimensional periodic function, we can use DCT. A DCT expresses a  sequence of data points in terms of a sum of cosine functions at different frequencies. \n",
    "\n",
    "$$DCT = \\displaystyle\\sum A * cos(fx)$$\n",
    "\n",
    "Where:\n",
    "- $A$: amplitude (height) of the cosine wave\n",
    "- $f$: frequency of the cosine wave \n",
    "- $x$: time\n",
    "\n",
    "This summation of cosine functions serves as a smoothed approximation of the entire original function.\n",
    "\n",
    "While DCT cannot be used for statistical inference to compare months like the ordinal piecewise, it's a predictive method to find a function to describe the data in general. DCT assumes regularity, so it won't do well to predict sudden changes year to year - it's good for long term sustainability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80511a",
   "metadata": {},
   "source": [
    "We implement the DCT by averaging coefficients across each year, by the month. The coefficients then, and their summation, would represent the average function of `totalschoolmeals` in a year. Doing this, only full years (in this instance 2021-2024) can be used to create the DCT function, but 2025 should be used to test it when it becomes avaliable. The graph below shows the summed DCT, along with all the cosine components that are summed to create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc33aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for DCT (years as rows, months as columns)\n",
    "\n",
    "reshaped_data_dct = school_meals[(school_meals['year'] >= 2021)].pivot_table(\n",
    "    index='year', \n",
    "    columns='month', \n",
    "    values='totalschoolmeals')\n",
    "\n",
    "reshaped_data_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c93f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the DCT along the month axis (axis=1) to examine monthly (seasonal) patterns\n",
    "dct_by_month = dct(reshaped_data_dct, type=2, axis=1, norm='ortho')\n",
    "\n",
    "# Average DCT coefficients across months\n",
    "average_dct = np.mean(dct_by_month, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ecf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot what the summed DCT equation looks like \n",
    "\n",
    "x = np.linspace(0, np.pi, 1000)\n",
    "y_total = np.zeros_like(x)  # Initialize y_total with zeros\n",
    "components = []\n",
    "\n",
    "# Define cosine components: (Amplitude, Frequency, Phase Shift)\n",
    "for f in range(0, len(average_dct)):\n",
    "    component = (average_dct[f], f)\n",
    "    components.append(component)\n",
    "\n",
    "# Add each cosine component to y_total\n",
    "for A, f in components:\n",
    "    y_total += A * np.cos(f * x)\n",
    "\n",
    "# Plot individual components - lines 16-20 can be commented out if the total sum is the only quantity of interest\n",
    "plt.figure(figsize=(10, 5))\n",
    "for A, f in components:\n",
    "    y = A * np.cos(f * x)\n",
    "    plt.plot(x, y, linestyle=\"dashed\", alpha=0.6, label=f\"A={A}, f={f}\")\n",
    "\n",
    "# Plot the total sum of cosine components\n",
    "plt.plot(x, y_total, color='black', linewidth=2, label=\"Sum of Components\")\n",
    "\n",
    "# Formatting the plot\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Summed Cosine Signal\")\n",
    "plt.title(\"Sum of Average DCT Components\")\n",
    "plt.legend()\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c244b",
   "metadata": {},
   "source": [
    "Thus, our resulting DCT equation is:\n",
    "\n",
    "$$D = 22354476.89 + 1019822.2 \\cos(x) + 2220334.5 \\cos(2x) - 1053467.71 \\cos(3x) - 4491778.09 \\cos(4x) + 2392015.99 \\cos(5x) + 1502551.19 \\cos(6x) - 1296155.11 \\cos(7x) - 1332900.25 \\cos(8x) - 168894.94 \\cos(9x) + 1202363.5 \\cos(10x) + 379204.3 \\cos(11x)$$\n",
    "\n",
    "Where:\n",
    "- $D$: the raw DCT prediction\n",
    "- $x$: a given point in time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5b204",
   "metadata": {},
   "source": [
    "Since the DCT predictions generated from summing up 12 cosine equations, the resulting raw predictions are too high. To normalize these predictions, we first transform the raw predictions to z-scores. Z-scores are a method of standardizing values using a distribution's mean and standard deviation. Raw scores are transformed into a measure that quantifies how many standard deviations a data point is from the mean:\n",
    "\n",
    "$$z = \\frac{D - M}{s}$$\n",
    "\n",
    "Where:\n",
    "\n",
    " - $z$: z-score\n",
    " - $D$: raw DCT prediction\n",
    " - $M$: mean of DCT raw predictions\n",
    " - $s$: standard deviation of DCT raw predictions\n",
    "\n",
    "From there, we can can transform the z-scores using a chosen mean and standard deviation to get the predicted total school meals for each month in a year on a more accurate scale. \n",
    "\n",
    "$$total school meals = M_{new} + z * s_{new}$$\n",
    "\n",
    "Where: \n",
    " - $z$: z-score\n",
    " - $M_{new}$: chosen mean of total school meals\n",
    " - $s_{new}$: chosen standard deviation of total school meals\n",
    "\n",
    "This allows for greater flexibility in how the DCT can be used. For example, if the ordinal piecewise function above suggests that total school meals across the years have been significantly increasing, one could increase the 2024's mean for 2025's predictions. Additionally, if Q1 predictions are higher than the actual values, the mean and standard deviation for Q2 predictions could consequently be adjusted as needed. \n",
    "\n",
    "Using this framework as a basis, we created two, slightly different models that use the same summed cosine equation, but slightly different approaches for the z-scores then obtained. Both model functions created (`school_meal_one_per_month` and `school_meal_average_per_month`) use 2021-2024's mean and standard deviation as default $M_{new}$ and $s_{new}$ parameters, unless otherwise specified.\n",
    "\n",
    "### Model 1: One Z-score Per Month \n",
    "\n",
    "The first model takes one single raw prediction (and z-score) for each given month in a year, for a total of 12 predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb4422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get predictions for a quarter\n",
    "def school_meal_one_per_month(months, mean = 'total', std_dev = 'total'):\n",
    "    \"\"\"\n",
    "    This function takes a list of months and returns their predicted total school meal amount.\n",
    "    \n",
    "    Args: \n",
    "        months (list): a list of 3 month's numerical values (can be more or less, but not empty)\n",
    "        mean (float): optional, default is set to the mean all school meals after 2020\n",
    "        std_dev (float): optional, default is set to the standard deviation of all school meals after 2020\n",
    "    \n",
    "    Returns:\n",
    "        specific_predictions (dict): a dictionary where keys correspond to months, and values correspond\n",
    "        to predicted total school meals.\n",
    "    \n",
    "    Examples:\n",
    "    Default - using total mean and total standard deviation:\n",
    "    >>> school_meal_one_per_month([1, 2, 3])\n",
    "    \n",
    "    {1: 6655274, 2: 6684396, 3: 8062922}\n",
    "    ------\n",
    "    Choosing a mean and standard deviation (2024):\n",
    "    >>> twentyfour_school = school_meals[(school_meals['year'] == 2024)]\n",
    "    >>> twentyfour_mean = twentyfour_school['totalschoolmeals'].mean()\n",
    "    >>> twentyfour_std = twentyfour_school['totalschoolmeals'].std()\n",
    "    >>> school_meal_one_per_month([1, 2, 3, 4, 5, 6, 7], twentyfour_mean, twentyfour_std)\n",
    "    \n",
    "    {1: 6905219, 2: 6933694, 3: 8281603, 4: 7456397, 5: 9540633, 6: 4570985, 7: 2190879}\n",
    "    \"\"\"\n",
    "    # Mapping months in the year to pi\n",
    "    dct_month_pi = np.pi / 11\n",
    "    dct_months = {m: (m - 1) * dct_month_pi for m in range(1, 13)}\n",
    "        \n",
    "    temp_school = school_meals[(school_meals['year'] >= 2021)]\n",
    "    \n",
    "    # Checking to see a mean/standard deviation were provided in parameters  \n",
    "    if mean == 'total' and std_dev == 'total':\n",
    "        # Get mean and sd from all total school meals for standardization\n",
    "        new_mean = temp_school['totalschoolmeals'].mean()\n",
    "        new_std = temp_school['totalschoolmeals'].std()\n",
    "    else:\n",
    "        new_mean = mean\n",
    "        new_std = std_dev\n",
    "\n",
    "    # Reshape data into appropriate format for DCT\n",
    "    reshaped_data_dct = temp_school.pivot_table(\n",
    "        index='year',\n",
    "        columns='month',\n",
    "        values='totalschoolmeals')\n",
    "    \n",
    "    dct_by_month = dct(reshaped_data_dct, type=2, axis=1, norm='ortho')\n",
    "    average_dct = np.mean(dct_by_month, axis = 0)\n",
    "    \n",
    "    # Getting dct predictions \n",
    "    yearly_prediction = {}\n",
    "    for month in dct_months:\n",
    "        dct_month = dct_months[month]\n",
    "        predicted_month_total = 0\n",
    "        for coefficient in range(0, 12):\n",
    "            predicted_month_total += average_dct[coefficient] * np.cos(coefficient * dct_month)\n",
    "        yearly_prediction[month] = round(predicted_month_total)\n",
    "    \n",
    "    # Compute dct predictions mean and standard deviation\n",
    "    dct_mean = np.mean(list(yearly_prediction.values()))\n",
    "    dct_std = np.std(list(yearly_prediction.values()))\n",
    "\n",
    "    # Standardize for school meals (dct prediction --> z-score --> total school meals)\n",
    "    standardized_score = {}\n",
    "    for month in yearly_prediction:\n",
    "        month_prediction = yearly_prediction[month]\n",
    "        z_score = (month_prediction - dct_mean)/dct_std\n",
    "        standardized = new_mean + (z_score * new_std)\n",
    "        standardized_score[month] = standardized\n",
    "    \n",
    "    # Return specific months requested\n",
    "    specific_predictions = {}\n",
    "    for month in months:\n",
    "        specific_predictions[month]= round(standardized_score[month])\n",
    " \n",
    "    return specific_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec1bdd",
   "metadata": {},
   "source": [
    "### Model 2: Averaging Z-scores Per Month \n",
    "\n",
    "The second model takes advantage of how the DCT treats the total school meals (Y) as continuous across time (X). Although the true data only has one data point per month in a year, a raw prediction for each day in the year can be taken from the DCT, for a total of 365 predictions. From there, a z-score is calculated for each day; those z-scores are mapped to their respective months, which are then averaged to get an averaged z-score for each month. For example, if one is interested in predicting total school meals for January 2025, the raw predictions from the first 31 days out of 365 are computed, transformed into z-scores, and then averaged to get one single z-score for January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b53d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get predictions for a quarter\n",
    "def school_meal_average_per_month(months, mean = 'total', std_dev = 'total'):\n",
    "    \"\"\"\n",
    "    This function takes a list of months and returns their predicted total school meal amount.\n",
    "    \n",
    "    Args: \n",
    "        months (list): a list of 3 month's numerical values (can be more or less, but not empty)\n",
    "        mean (float): optional, default is set to the mean all school meals after 2020\n",
    "        std_dev (float): optional, default is set to the standard deviation of all school meals after 2020\n",
    "    \n",
    "    Returns:\n",
    "        specific_predictions (dict): a dictionary where keys correspond to months, and values correspond\n",
    "        to predicted total school meals.\n",
    "    \n",
    "    Examples:\n",
    "    Default - using total mean and total standard deviation:\n",
    "    >>> school_meal_average_per_month([1, 2, 3])\n",
    "    \n",
    "    {1: 6528038, 2: 7202481, 3: 7717102}\n",
    "    ------\n",
    "    Choosing a mean and standard deviation (2024):\n",
    "    >>> twentyfour_school = school_meals[(school_meals['year'] == 2024)]\n",
    "    >>> twentyfour_mean = twentyfour_school['totalschoolmeals'].mean()\n",
    "    >>> twentyfour_std = twentyfour_school['totalschoolmeals'].std()\n",
    "    >>> school_meal_average_per_month([1, 2, 3, 4, 5, 6, 7], twentyfour_mean, twentyfour_std)\n",
    "    \n",
    "    {1: 6780809, 2: 7440273, 3: 7943463, 4: 7777536, 5: 8987135, 6: 4738723, 7: 2419123}\n",
    "    \"\"\"\n",
    "    # Mapping days in the year to pi\n",
    "    dct_days_pi = np.pi / 364\n",
    "    dct_days = {m: (m - 1) * dct_days_pi for m in range(1, 366)}\n",
    "        \n",
    "    temp_school = school_meals[(school_meals['year'] >= 2021)]\n",
    "    \n",
    "    # Checking to see a mean/standard deviation were provided in parameters  \n",
    "    if mean == 'total' and std_dev == 'total':\n",
    "        # Get mean and sd from all total school meals for standardization\n",
    "        new_mean = temp_school['totalschoolmeals'].mean()\n",
    "        new_std = temp_school['totalschoolmeals'].std()\n",
    "    else:\n",
    "        new_mean = mean\n",
    "        new_std = std_dev\n",
    "\n",
    "    # Reshape data into appropriate format for DCT\n",
    "    reshaped_data_dct = temp_school.pivot_table(\n",
    "        index='year',\n",
    "        columns='month',\n",
    "        values='totalschoolmeals')\n",
    "    \n",
    "    dct_by_month = dct(reshaped_data_dct, type=2, axis=1, norm='ortho')\n",
    "    average_dct = np.mean(dct_by_month, axis = 0)\n",
    "    \n",
    "    # Getting dct predictions \n",
    "    raw_yearly_prediction = []\n",
    "    for day in dct_days:\n",
    "        dct_day = dct_days[day]\n",
    "        predicted_day_total = 0\n",
    "        for coefficient in range(0, 12):\n",
    "            predicted_day_total += average_dct[coefficient] * np.cos(coefficient * dct_day)\n",
    "        raw_yearly_prediction.append(round(predicted_day_total))\n",
    "    \n",
    "    # map 365 days to respective months\n",
    "    days_to_year = {1: 31, 2: 59, 3: 90, 4: 120, 5: 151, 6: 181, 7:212, 8: 243, 9: 273, 10: 304, 11: 334, 12: 365}\n",
    "    days_to_year_keys = list(days_to_year.keys())\n",
    "    days_to_year_values = list(days_to_year.values())\n",
    "    all_months = []\n",
    "    all_days = []\n",
    "    for day in range(1, 366):\n",
    "        if day <= days_to_year_values[0]:\n",
    "            all_months.append(days_to_year_keys[0])\n",
    "            all_days.append(day)\n",
    "        else:\n",
    "            days_to_year_values = days_to_year_values[1:]\n",
    "            days_to_year_keys = days_to_year_keys[1:]\n",
    "            all_months.append(days_to_year_keys[0])\n",
    "            all_days.append(day)\n",
    "\n",
    "    test_df = pd.DataFrame()\n",
    "    test_df['months'] = all_months\n",
    "    test_df['days'] = all_days\n",
    "    test_df['raw_predictions'] = raw_yearly_prediction\n",
    "    \n",
    "    # Compute dct predictions mean and standard deviation\n",
    "    raw_dct_mean = np.mean(raw_yearly_prediction)\n",
    "    raw_dct_std = np.std(raw_yearly_prediction)\n",
    "\n",
    "    # Get z-scores for school meals per day (dct prediction --> z-score)\n",
    "    z_scores = []\n",
    "    for day in raw_yearly_prediction:\n",
    "        z_scores.append((day - raw_dct_mean)/raw_dct_std)\n",
    "        \n",
    "    test_df['z_scores'] = z_scores\n",
    "    \n",
    "    averaged_by_month = test_df.groupby('months').mean().reset_index()\n",
    "    avg_z_scores = list(averaged_by_month['z_scores'])\n",
    "\n",
    "    standardized_predictions = {}\n",
    "    for month in range(0, 12):\n",
    "        z_score = avg_z_scores[month]\n",
    "        standardized_score = new_mean + (z_score * new_std)\n",
    "        standardized_predictions[month + 1] = round(standardized_score, 2)\n",
    "\n",
    "    # Return specific months requested\n",
    "    specific_predictions = {}\n",
    "    for month in months:\n",
    "        specific_predictions[month]= round(standardized_predictions[month])\n",
    "\n",
    "    return specific_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1eccf1",
   "metadata": {},
   "source": [
    "### Model Performance and Selection: \n",
    "\n",
    "With these two models, it is imperative to test each model's performance, and additionally test which $M_{new}$ and $s_{new}$ yield the best predictions. \n",
    "\n",
    "Note, ideally this would be done using test data (i.e., data that was not used to create the model) to protect against model overfitting; however, due to the limited number of total data points avaliable, we decided to test performance using training data only. Given the way the DCT is calculated, creating a train/test split would leave only 36 data points to create the models, since they require full year of data to be included. Thus, we proceeded with utilizing all 48 data points to develop and evaluate the models, while acknowledging that future validation and model selection will require testing against 2025 Quarter 1 data once it becomes available in July.\n",
    "\n",
    "With this limitation in mind, we tested 3 general mean and standard deviation scenarios for each model, computing both the mean squared error (MSE) and the root mean squared error (RMSE) in each one. \n",
    "\n",
    "#### Baseline: Using Each Year's Respective Mean and SD\n",
    "\n",
    "We first tested each model using each year's respective mean and standard deviation. For example, 2021's predictions were calculated using 2021's mean and standard deviation. The MSE and RMSE computed for both models serves as a baseline as it represents the average error for the \"best\" predictions these models can produce. In practice though, this is using information that SDHC won't necessarily have, as they won't have 2025's mean and standard deviation to predict 2025 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f544ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mse_school_meals = school_meals[(school_meals['year'] >= 2021)].copy()\n",
    "years = [2021, 2022, 2023, 2024]\n",
    "one_predicted_meals = []\n",
    "avg_predicted_meals = []\n",
    "\n",
    "for year in years:\n",
    "    # Calculate the mean and standard deviation for a given year\n",
    "    temp_year = school_meals[(school_meals['year'] == year)]\n",
    "    temp_mean = temp_year['totalschoolmeals'].mean()\n",
    "    temp_std = temp_year['totalschoolmeals'].std()\n",
    "    # Get year's predictions using specific mean and standard deviation\n",
    "    one_year_predictions = list(school_meal_one_per_month([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], temp_mean, temp_std).values())\n",
    "    one_predicted_meals.extend(one_year_predictions)\n",
    "    avg_year_predictions = list(school_meal_average_per_month([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], temp_mean, temp_std).values())\n",
    "    avg_predicted_meals.extend(avg_year_predictions)\n",
    "baseline_mse_school_meals['one_z_pred_meals'] = one_predicted_meals\n",
    "baseline_mse_school_meals['average_z_pred_meals'] = avg_predicted_meals\n",
    "\n",
    "one_z_mse = round(((baseline_mse_school_meals['totalschoolmeals'] - baseline_mse_school_meals['one_z_pred_meals'])**2).mean(), 2)\n",
    "one_z_rmse = round(np.sqrt(one_z_mse), 2)\n",
    "avg_z_mse = round(((baseline_mse_school_meals['totalschoolmeals'] - baseline_mse_school_meals['average_z_pred_meals'])**2).mean(), 2)\n",
    "avg_z_rmse = round(np.sqrt(avg_z_mse), 2)\n",
    "\n",
    "print('Baseline: Respective Year Mean and SD:')\n",
    "print('\\n')\n",
    "print('One Z-score Model MSE: ' + str(one_z_mse))\n",
    "print('One Z-score Model RMSE: ' + str(one_z_rmse))\n",
    "print('Average Z-score Model MSE: ' + str(avg_z_mse))\n",
    "print('Average Z-score Model RMSE: ' + str(avg_z_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43be6074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_mse_school_meals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Actual school meals\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(\n\u001b[1;32m      6\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotalschoolmeals\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 7\u001b[0m     data\u001b[38;5;241m=\u001b[39mbaseline_mse_school_meals,\n\u001b[1;32m      8\u001b[0m     marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m     label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Predicted school meals\u001b[39;00m\n\u001b[1;32m     13\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(\n\u001b[1;32m     14\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone_z_pred_meals\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m     data\u001b[38;5;241m=\u001b[39mbaseline_mse_school_meals,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m     label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel 1 Predicted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'baseline_mse_school_meals' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Actual school meals\n",
    "sns.lineplot(\n",
    "    x='date', y='totalschoolmeals',\n",
    "    data=baseline_mse_school_meals,\n",
    "    marker='o',\n",
    "    color = 'gray',\n",
    "    label='Actual')\n",
    "\n",
    "# Predicted school meals\n",
    "sns.lineplot(\n",
    "    x='date', y='one_z_pred_meals',\n",
    "    data=baseline_mse_school_meals,\n",
    "    marker='o',\n",
    "    color = '#ed7d31',\n",
    "    linestyle=':',\n",
    "    label='Model 1 Predicted')\n",
    "\n",
    "sns.lineplot(\n",
    "    x='date', y='average_z_pred_meals',\n",
    "    data=baseline_mse_school_meals,\n",
    "    marker='o',\n",
    "    color = '#789C4B',\n",
    "    linestyle='--',\n",
    "    label='Model 2 Predicted')\n",
    "\n",
    "ax.set_title('San Diego School Meals Over Time - Using Respective Year Mean and SD')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('School Meals (in millions)')\n",
    "\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: (x/1000000)))\n",
    "\n",
    "# major ticks = years\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month=7, day = 15))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "ax.tick_params(axis='x', which='major', pad=25)\n",
    "\n",
    "# minor ticks = months\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b'))\n",
    "\n",
    "ax.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de41d1",
   "metadata": {},
   "source": [
    "#### Scenario 1: Using the Previous Year's Mean and SD \n",
    "\n",
    "The first practical scenario for the mean and standard deviation we tested was using the previous year's mean and standard deviation. For example, using 2021's mean and standard deviation for 2022's predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc573b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_mse_school_meals = school_meals[(school_meals['year'] >= 2021)].copy()\n",
    "year_after = school_meals[(school_meals['year'] >= 2022)].copy()\n",
    "years = [2021, 2022, 2023]\n",
    "one_predicted_meals = []\n",
    "avg_predicted_meals = []\n",
    "\n",
    "for year in years:\n",
    "    # Calculate the mean and standard deviation for a given year\n",
    "    temp_year = school_meals[(school_meals['year'] == year)]\n",
    "    temp_mean = temp_year['totalschoolmeals'].mean()\n",
    "    temp_std = temp_year['totalschoolmeals'].std()\n",
    "    # Get year's predictions using specific mean and standard deviation\n",
    "    one_year_predictions = list(school_meal_one_per_month([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], temp_mean, temp_std).values())\n",
    "    one_predicted_meals.extend(one_year_predictions)\n",
    "    \n",
    "    avg_year_predictions = list(school_meal_average_per_month([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], temp_mean, temp_std).values())\n",
    "    avg_predicted_meals.extend(avg_year_predictions)\n",
    "    \n",
    "year_after['one_z_pred_meals'] = one_predicted_meals\n",
    "year_after['avg_z_pred_meals'] = avg_predicted_meals\n",
    "\n",
    "one_z_mse = round(((year_after['totalschoolmeals'] - year_after['one_z_pred_meals'])**2).mean(), 2)\n",
    "one_z_rmse = round(np.sqrt(one_z_mse), 2)\n",
    "avg_z_mse = round(((year_after['totalschoolmeals'] - year_after['avg_z_pred_meals'])**2).mean(), 2)\n",
    "avg_z_rmse = round(np.sqrt(avg_z_mse), 2)\n",
    "\n",
    "print('Scenario 1: Previous Year Mean and SD:')\n",
    "print('\\n')\n",
    "print('One Z-score Model MSE: ' + str(one_z_mse))\n",
    "print('One Z-score Model RMSE: ' + str(one_z_rmse))\n",
    "print('Average Z-score Model MSE: ' + str(avg_z_mse))\n",
    "print('Average Z-score Model RMSE: ' + str(avg_z_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e956a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Actual school meals\n",
    "sns.lineplot(\n",
    "    x='date', y='totalschoolmeals',\n",
    "    data=year_after,\n",
    "    marker='o',\n",
    "    color = 'gray',\n",
    "    label='Actual')\n",
    "\n",
    "# Predicted school meals\n",
    "sns.lineplot(\n",
    "    x='date', y='one_z_pred_meals',\n",
    "    data=year_after,\n",
    "    marker='o',\n",
    "    color = '#ed7d31',\n",
    "    linestyle=':',\n",
    "    label='Model 1 Predicted')\n",
    "\n",
    "sns.lineplot(\n",
    "    x='date', y='avg_z_pred_meals',\n",
    "    data=year_after,\n",
    "    marker='o',\n",
    "    color = '#789C4B',\n",
    "    linestyle='--',\n",
    "    label='Model 2 Predicted')\n",
    "\n",
    "ax.set_title(\"San Diego School Meals Over Time - Using the Previous Year's Mean and SD\")\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('School Meals (in millions)')\n",
    "\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: (x/1000000)))\n",
    "\n",
    "# major ticks = years\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month=7, day = 15))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "ax.tick_params(axis='x', which='major', pad=25)\n",
    "\n",
    "# minor ticks = months\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b'))\n",
    "\n",
    "ax.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3112d79d",
   "metadata": {},
   "source": [
    "#### Scenario 2: Using 2021-2024's Mean and and SD\n",
    "The second practical scenario for the mean and standard deviation we tested was using all monthly school meals across 2021-2024 to compute their mean and standard deviation. For example, using 2021-2024's mean and standard deviation for 2021's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc768199",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mse_school_meals = school_meals[(school_meals['year'] >= 2021)].copy()\n",
    "years = [2021, 2022, 2023, 2024]\n",
    "one_predicted_meals = []\n",
    "avg_predicted_meals = []\n",
    "\n",
    "for year in years:\n",
    "    one_year_predictions = list(school_meal_one_per_month([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]).values())\n",
    "    one_predicted_meals.extend(one_year_predictions)\n",
    "    avg_year_prediction = list(school_meal_average_per_month([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]).values())\n",
    "    avg_predicted_meals.extend(avg_year_predictions)\n",
    "    \n",
    "all_mse_school_meals['one_z_pred_meals'] = one_predicted_meals\n",
    "all_mse_school_meals['avg_z_pred_meals'] = avg_predicted_meals\n",
    "\n",
    "one_z_mse = round(((all_mse_school_meals['totalschoolmeals'] - all_mse_school_meals['one_z_pred_meals'])**2).mean(), 2)\n",
    "one_z_rmse = round(np.sqrt(one_z_mse), 2)\n",
    "avg_z_mse = round(((all_mse_school_meals['totalschoolmeals'] - all_mse_school_meals['avg_z_pred_meals'])**2).mean(), 2)\n",
    "avg_z_rmse = round(np.sqrt(avg_z_mse), 2)\n",
    "\n",
    "print('Scenario 2: 2021-2024 Mean and SD:')\n",
    "print('\\n')\n",
    "print('One Z-score Model MSE: ' + str(one_z_mse))\n",
    "print('One Z-score Model RMSE: ' + str(one_z_rmse))\n",
    "print('Average Z-score Model MSE: ' + str(avg_z_mse))\n",
    "print('Average Z-score Model RMSE: ' + str(avg_z_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38dc5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Actual school meals\n",
    "sns.lineplot(\n",
    "    x='date', y='totalschoolmeals',\n",
    "    data=all_mse_school_meals,\n",
    "    marker='o',\n",
    "    color = 'gray',\n",
    "    label='Actual'\n",
    ")\n",
    "\n",
    "# Predicted school meals\n",
    "sns.lineplot(\n",
    "    x='date', y='one_z_pred_meals',\n",
    "    data=all_mse_school_meals,\n",
    "    marker='o',\n",
    "    color = '#ed7d31',\n",
    "    linestyle=':',\n",
    "    label='Model 1 Predicted')\n",
    "\n",
    "sns.lineplot(\n",
    "    x='date', y='avg_z_pred_meals',\n",
    "    data=all_mse_school_meals,\n",
    "    marker='o',\n",
    "    color = '#789C4B',\n",
    "    linestyle='--',\n",
    "    label='Model 2 Predicted')\n",
    "\n",
    "ax.set_title('San Diego School Meals Over Time - Using 2021-2024 Mean and SD')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('School Meals (in millions)')\n",
    "\n",
    "# major ticks = years\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month=7, day = 15))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "ax.tick_params(axis='x', which='major', pad=25)\n",
    "\n",
    "# minor ticks = months\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b'))\n",
    "\n",
    "ax.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a100d",
   "metadata": {},
   "source": [
    "### Performance Summary:\n",
    "\n",
    "The table below provides a summary of each model's RMSE in each scenario described above. It becomes clear that Model 2, the averaged z-score per month, performs better than Model 1 on the available data. Regardless of the scenario, Model 2 has lower RMSE values. In regards to which mean and standard deviation to use, Scenario 2 (2021-2024's mean and standard deviation) leads to a better RMSE than Scenario 1. Additionally, Model 2 using Scenario 2's Mean/SD yields a lower RMSE than Model 1's baseline, suggesting that practically, Model 2 will perform better than Model 1, even when Model 1 has \"more information.\"\n",
    "\n",
    "\n",
    "| Mean/SD                                 | Model 1: One Z-score  | Model 2: Average Z-score |\n",
    "| --------------------------------------- | --------------------- | ------------------------ |\n",
    "| **Baseline:** Respective Year's Mean/SD |       656737.88       |         540,895.58       |\n",
    "| **Scenario 1:** Previous Year's Mean/SD |       780,745.69      |         708,325.42       |\n",
    "| **Scenario 2:** 2021-2024 Mean/SD       |       718,575.43      |       **642,800.40**     |\n",
    "\n",
    "Thus, with these metrics, we argue that in general, Model 2 with 2021-2024's mean and standard deviation should be used to generate predictions for total school meals for Q1 of 2025.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ba2e1",
   "metadata": {},
   "source": [
    "# 5. Discussion and Conclusion\n",
    "\n",
    "Our project successfully calculated a new FPL of 225% to define nutrition insecurity in San Diego Country to update SDHC's methodology.\n",
    "\n",
    "In regards to predictive models, our first model, the multiple linear regression, developed to predict CalFresh allotments in California showed how there is an upward trend in allotments over time. To reflect shifts in the data from policy motions, we introduced dummy variables in our second multiple linear regression. Although we did see improved model accuracy, the regression model did not see improvement in the low Durbin-Watson statistics. The errors in the prediction were autocorrelated which suggests that the model does not do well in short term predictions with sudden spikes/drops and would better suit long term growth predictions. \n",
    "\n",
    "Additionally, we successfully developed two models to analyze total school meal distributions. The first, an ordinal piecewise model, offers valuable insights into whether the number of meals provided differs significantly from previous months or years. The second, a Discrete Cosine Transform (DCT) model, demonstrates strong predictive accuracy on in-sample data and is particularly well-suited for forecasting purposes. The San Diego Hunger Coalition plans to implement this model to streamline their operations and reduce reporting delays by approximately three months.\n",
    "\n",
    "## 5.1 Limitations\n",
    "\n",
    "While our research and predictive models provide a strong foundation for improving food assistance engagement and forecasting, there are several limitations that should be noted. One of the most significant limitations we faced was the lack of data availability. For our school meals data, we were only able to train our models on four full years worth of data, summing to 48 total datapoints. It is also important to note that most of these years' data are largely impacted by the COVID-19 pandemic and its effects on food assistance programs. This limited our ability to capture long-term data trends and improve the DCT Models' predictive accuracy. Furthermore, as previously discussed, it is unclear how well the DCT Model's perform out of sample due to the lack of data; quarter 1 data will become avaliable after this project has concluded. \n",
    "\n",
    "Additionally, our analysis relies on data that may be prone to reporting inconsistencies and missing values that can vary by school, program, and year. This could impact the quality of the data our models are built upon, and can affect the prediction accuacy and applicability of our models to future data. Further, factors such as COVID-19 impacts, school closures, and potential program eligibility changes were not directly captured in the modeling. \n",
    "\n",
    "The predictive model for CalFresh faced similar limitations, with only three years worth of data to work on. This is a realtively small sample for a time series analysis model, such as ARIMA, that requires a sufficient amount of data to detect patterns in the lags through estimates of autoregressive, moving average, and seasonal components.\n",
    "\n",
    "In response to feedback, an ARIMA model with drift was added to the appendix. The ARIMA model's high RMSE compared to the original regression model suggests limited predictive performance. This may be due to the small sample size and demonstrated lack of autocorrelation in the data. In addition to the ARIMA model, a linear regression model that accounts for seasonality was generated using year specific quarters as categorical variables. While this model showed the best predictive accuracy, the trade-off is that individual months become less interpretable - especially in months where there are emergency allotments.\n",
    "\n",
    "Furthermore, when taking into account the unpredictability of natural disasters or political events, linear models are not able capture these spikes or drops in data. The approach to capturing these events are simplified as dummy variables which may not be the best approach as we do not fully capture the potential prolonged effects it may have over time.\n",
    "\n",
    "\n",
    "## 5.2 Future Areas of Research\n",
    "\n",
    "Future work can build upon the FPL research and food assistance models we developed, especially by integrating more training data to improve the quality of our models. In particular, training the DCT model on additional years' data will improve the model's accuracy. Expanding upon our training data is essential in developing robust models that can learn from long-term trends, therefore producing more usable predictions. Additionally, analyzing the DCT model's performance on out of sample data is key to gaining a better understanding of how well the model capture's total school meals. Once actual 2025 data becomes avaliable, the mean squared error and/or root mean squared error should be calculated to more objectively evaluate the DCT models' peformance. If the DCT doesn't yield accurate enough predictions, additional models using methods that leverage the data's periodicity, such as a Discrete Fourier Transform, can be developed and tested. \n",
    "\n",
    "Further, future models can integrate other variables, allowing a more granular view of the data. For example, including valuable information about zipcode and school level would allow San Diego Hunger Coalition to explore how trends vary between areas and grade levels. This granularity could be included in interactive and informative Tableau or Power BI dashboards to allow a viewer to examine nutrition insecurity data on a zipcode, city, or overall county view. \n",
    "\n",
    "The CalFresh Allotment prediction model would also benefit from having additional years of data. The implementation of an ARIMA model with more data points may address the autocorrelation in the data and improve short term forecasting. Additionally, the integration of additional variables, such as demographic data and unemployment rates, would allow for a better understanding of the fluctuations in allotments. For example, it could create an opportunity to explore how economic conditions affects CalFresh usage or funding which in turn may enhance the value of what the model has to offer to policy makers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b4211-0367-4034-8931-842eb0e2ee4e",
   "metadata": {},
   "source": [
    "# 6. Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a4185-9d5a-455f-93c4-9fa02a27f9d2",
   "metadata": {},
   "source": [
    "California Governor’s Office of Emergency Services. “2024 Storms Recovery Resources.” Cal OES News, 1 Mar. 2024, https://news.caloes.ca.gov/2024stormrecovery/.\n",
    "\n",
    "\"Consumer Price Index: Questions and Answers.\" U.S. Bureau of Labor Statistics, U.S. Department of Labor, https://www.bls.gov/cpi/questions-and-answers.htm. Accessed 5 June 2025.\n",
    "\n",
    "Fisher, Gordon M. “Fisher on Poverty: The Development and History of the U.S. Poverty Thresholds.” Social Security Administration, https://www.ssa.gov/history/fisheronpoverty.html.\n",
    "\n",
    "Legal Services of Northern California. “Benefit Increases Because of COVID-19.” LSNC Guide to CalFresh Benefits, https://calfresh.guide/benefit-increase-because-of-covid-19/.\n",
    "\n",
    "U.S. Department of Health and Human Services. “Frequently Asked Questions Related to the Poverty Guidelines and Poverty.” Office of the Assistant Secretary for Planning and Evaluation (ASPE), https://aspe.hhs.gov/topics/poverty-economic-mobility/poverty-guidelines/frequently-asked-questions-related-poverty-guidelines-poverty#differences.\n",
    "\n",
    "U.S. Department of Health and Human Services. “Prior HHS Poverty Guidelines and Federal Register References.” ASPE, https://aspe.hhs.gov/topics/poverty-economic-mobility/poverty-guidelines/prior-hhs-poverty-guidelines-federal-register-references."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14f3eb3-4204-4937-ae6e-b5eb6db401ab",
   "metadata": {},
   "source": [
    "# 7. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6969bd5-19a8-4820-8642-41315e18bd2a",
   "metadata": {},
   "source": [
    "## Additional Model Testing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd5f07-062b-43bf-889f-4db1ef2fa1b7",
   "metadata": {},
   "source": [
    "#### ARIMA Model\n",
    "---\n",
    "#### Check for stationarity and perform differencing if necessary:\n",
    "\n",
    "Data has to be stationary, the Augmented Dickey-Fuller test is used to see if the data has a constant mean and variance, and put numbers to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe12786-cba8-47c0-b1c8-4abaf33835ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of the original df\n",
    "arimatotals22_24 = totals22_24.copy()\n",
    "\n",
    "result_original = adfuller(arimatotals22_24[\"CountyTotal\"])\n",
    "\n",
    "print(f\"ADF Statistic (Original): {result_original[0]:.4f}\")\n",
    "print(f\"p-value (Original): {result_original[1]:.4f}\")\n",
    "\n",
    "if result_original[1] < 0.05:\n",
    "    print(\"Interpretation: The original series is Stationary.\\n\")\n",
    "else:\n",
    "    print(\"Interpretation: The original series is Non-Stationary.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ffd9e-a8af-45f5-b880-b48b8749764f",
   "metadata": {},
   "source": [
    "To perform differencing, we subtract each observation from the previous one to give us a new time series of first differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0d9ca-cdc5-4a65-8868-07269b5bd1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply first-order differencing\n",
    "arimatotals22_24['CountyTotal_Diff'] = arimatotals22_24['CountyTotal'].diff()\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller test on the differenced series\n",
    "result_diff = adfuller(arimatotals22_24[\"CountyTotal_Diff\"].dropna())\n",
    "print(f\"ADF Statistic (Differenced): {result_diff[0]:.4f}\")\n",
    "print(f\"p-value (Differenced): {result_diff[1]:.4f}\")\n",
    "if result_diff[1] < 0.05:\n",
    "    print(\"Interpretation: The differenced series is Stationary.\")\n",
    "else:\n",
    "    print(\"Interpretation: The differenced series is Non-Stationary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167fc50b-38b3-47de-b956-fef3d0216e66",
   "metadata": {},
   "source": [
    "---\n",
    "#### Plotting Differenced County Total Allotments Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40715a23-63ba-45b0-86e6-fa481ee9ade3",
   "metadata": {},
   "source": [
    "Plot is showing how much CalFresh Allotment totals are changing from month to month. It captures the spikes in emergency allotment months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d34210-bfc6-4560-bdab-39429858f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the differenced County Total Allotments\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Creating a line plot: Credit to Amy for code block\n",
    "ax = sns.lineplot(x='Date', y='CountyTotal_Diff', data= arimatotals22_24, marker='o')\n",
    "ax.set_title('Differenced County Total Allotments Over Time')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Differenced County Total Allotments')\n",
    "\n",
    "# Uncomment line below for y-axis in millions\n",
    "#ax.ticklabel_format(style='plain', axis='y')  \n",
    "\n",
    "# Setting respective years on x-axis\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month=7, day = 15))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "ax.tick_params(axis='x', which='major', pad=25) # space between years and months\n",
    "\n",
    "# Setting respective months on x-axis\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())  \n",
    "ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b')) \n",
    "\n",
    "\n",
    "sns.despine() \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daebbf16-1b9f-4940-9ddd-2afa08ddf2dd",
   "metadata": {},
   "source": [
    "---\n",
    "#### Model identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26e3f2-c796-4415-9915-8efdf4f59681",
   "metadata": {},
   "source": [
    "ACF (Autocorrelation Function) and PACF (Partial Autocorrelation Function) is used to deterime values of p, d, and q. \n",
    "\n",
    "- Where \"p\" is the number of lagged observations. \n",
    "- Where \"d\" refers to the order of differencing.\n",
    "- Where \"q\" refers to the order of the moving average (MA) part of the model.\n",
    "\n",
    "For our data, we choose 1 for both p and q because we see a significant spike in the first lag for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca69e2a7-f532-41f4-9157-edaf262c7c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF for the differenced series\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# ACF plot\n",
    "plot_acf(arimatotals22_24['CountyTotal_Diff'].dropna(), lags=1, ax=axes[0])\n",
    "axes[0].set_title('Autocorrelation Function (ACF)')\n",
    "\n",
    "# PACF plot\n",
    "plot_pacf(arimatotals22_24['CountyTotal_Diff'].dropna(), lags=1, ax=axes[1])\n",
    "axes[1].set_title('Partial Autocorrelation Function (PACF)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394e2b8-9055-4c9a-a02d-90d0e34ea870",
   "metadata": {},
   "source": [
    "---\n",
    "#### Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da3a50-46a7-4b7b-8059-da89be49018d",
   "metadata": {},
   "source": [
    "We use the fitted model to predict future values based on the data. We then visualize predictions by plotting the predicted values alongside the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6001a459-4384-4e3c-9a46-28cdf2758df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "train_size = int(len(arimatotals22_24) * 0.8)\n",
    "train, test = arimatotals22_24.iloc[:train_size], arimatotals22_24.iloc[train_size:]\n",
    "\n",
    "# Fit ARIMA model\n",
    "model_arima = ARIMA(train[\"CountyTotal\"], order=(1,1,1),trend='t')\n",
    "model_arima_fit = model_arima.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72805d-937a-4eae-a7b2-90acf82ceb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train dates:\", train[\"Date\"].min(), \"to\", train[\"Date\"].max())\n",
    "print(\"Test dates:\", test[\"Date\"].min(), \"to\", test[\"Date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a80c8-bf57-4e16-a698-f3e9fce0ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "forecast = model_arima_fit.forecast(steps=len(test))\n",
    "forecast.index = test[\"Date\"].values \n",
    "\n",
    "# Plot the results with specified colors\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(train.index, train[\"CountyTotal\"], label='Train', color='#203147')\n",
    "plt.plot(test.index, test[\"CountyTotal\"], label='Test', color='#01ef63')\n",
    "plt.plot(test.index, forecast, label='Forecast', color='orange')\n",
    "plt.title('CalFresh Allotment Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Allotment')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf49e9-2e71-4eb7-b0e5-22e9a50d82b5",
   "metadata": {},
   "source": [
    "---\n",
    "#### Evaluating ARIMA Model Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658f2cf-91b3-44e2-943e-5bc8452e3d73",
   "metadata": {},
   "source": [
    "Lower values mean the model fits better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb2263-b8cf-4d5f-900a-c6dd56ecfead",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AIC: {model_arima_fit.aic}\")\n",
    "print(f\"BIC: {model_arima_fit.bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f90ed4-8f19-4abc-86e8-9a374d6222d2",
   "metadata": {},
   "source": [
    "A lower RMSE indicates a better ARIMA model, reflecting smaller differences between actual and predicted values, and it's on the scale of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d74d78-4244-4a29-af6d-ce41ac9529d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = forecast[:len(test)]\n",
    "test_close = test[\"CountyTotal\"][:len(forecast)]\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_close, forecast))\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e58cb-ea55-4e2e-86e6-b40df1e65011",
   "metadata": {},
   "source": [
    "---\n",
    "#### Linear Regression Model Statistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8d205-7205-4c1c-a0ae-724acc5318f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data (same as ARIMA)\n",
    "train_size = int(len(totals22_24) * 0.8)\n",
    "reg_train = totals22_24.iloc[:train_size]\n",
    "reg_test = totals22_24.iloc[train_size:]\n",
    "\n",
    "# Predict on test set\n",
    "reg_preds = model_2.predict(reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e1698-cb72-4b26-a8a1-f9a18e7fd3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_rmse = np.sqrt(mean_squared_error(reg_test[\"CountyTotal\"], reg_preds))\n",
    "print(f\"Linear Regression RMSE: {reg_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c553bc-6717-44dd-99ea-09a61561bfb3",
   "metadata": {},
   "source": [
    "---\n",
    "#### Multiple Linear Regression w/ Quarter Dummies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b619cd3e-b0fe-4ae4-b82a-86056534d39b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'totals22_24' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# creating a copy of the df\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m totals22_24_q \u001b[38;5;241m=\u001b[39m totals22_24\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Extracting quarters\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#totals22_24_q[\"quarter_label\"] = (\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#totals22_24_q[\"Date\"].dt.year.astype(str) + \"_Q\" + totals22_24_q[\"Date\"].dt.quarter.astype(str))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Extract quarter in the format '2022Q1', '2023Q2'\u001b[39;00m\n\u001b[1;32m      9\u001b[0m totals22_24_q[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m totals22_24_q[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mto_period(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'totals22_24' is not defined"
     ]
    }
   ],
   "source": [
    "# creating a copy of the df\n",
    "totals22_24_q = totals22_24.copy()\n",
    "\n",
    "# Extracting quarters\n",
    "#totals22_24_q[\"quarter_label\"] = (\n",
    "    #totals22_24_q[\"Date\"].dt.year.astype(str) + \"_Q\" + totals22_24_q[\"Date\"].dt.quarter.astype(str))\n",
    "\n",
    "# Extract quarter in the format '2022Q1', '2023Q2'\n",
    "totals22_24_q[\"quarter\"] = totals22_24_q[\"Date\"].dt.to_period(\"Q\").astype(str)\n",
    "\n",
    "model_quarter = smf.ols( data = totals22_24_q, formula = \"CountyTotal ~ C(quarter) + year + emergency_allotments + covid_end\").fit()\n",
    "\n",
    "model_quarter.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e776359f-2e9b-4c94-ab06-05e4355b8810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on last 20% of data\n",
    "train_size = int(len(totals22_24_q) * 0.8)\n",
    "q_train = totals22_24_q.iloc[:train_size]\n",
    "q_test = totals22_24_q.iloc[train_size:]\n",
    "    \n",
    "# Predict\n",
    "quarter_preds = model_quarter.predict(q_test)\n",
    "\n",
    "# RMSE\n",
    "rmse_quarter = np.sqrt(mean_squared_error(test_q[\"CountyTotal\"], quarter_preds))\n",
    "print(f\"Quarter-based Regression RMSE: {rmse_quarter:.2f}\")\n",
    "\n",
    "\n",
    "#Quarter-based Regression RMSE: 1547586.52\n",
    "#Quarter-based Regression RMSE: 203078.71"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb068e-70f0-4564-9ef4-dd729cefc276",
   "metadata": {},
   "source": [
    "Looking at RMSE for all models, quarter based regression seems to be preforming best.\n",
    "\n",
    "* Quarter-based Regression RMSE: 203078.71\n",
    "\n",
    "    AIC: 1099\n",
    "* Linear Regression RMSE: 924008.77\n",
    "  \n",
    "    AIC: 1163\n",
    "* ARIMA RMSE: 1091056.0138\n",
    "\n",
    "    AIC: 876"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
